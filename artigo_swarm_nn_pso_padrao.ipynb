{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (12.0, 9.0) # set default size of plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "###  Modelo para Regressão Com backpropagation\n",
    "\n",
    "def layer_sizes2(X, Y, n_h=4):\n",
    "    \"\"\"\n",
    "    Argumentos:\n",
    "    X -- shape do input (quantidade de features, quantidade de exemplos)\n",
    "    Y -- shape do target (1, quantidade de exemplos)\n",
    "    \"\"\"\n",
    "    n_x = X.shape[0]\n",
    "    n_y = Y.shape[0]\n",
    "    return (n_x, n_h, n_y)\n",
    "\n",
    "def initialize_parameters2(n_x, n_h, n_y):\n",
    "    \"\"\"\n",
    "    Argument:\n",
    "    n_x -- tamanho da camada de entrada\n",
    "    n_h -- tamanho da camada escondida\n",
    "    n_y -- tamanho da camada de saída\n",
    "    \n",
    "    Retorna:\n",
    "    params -- dicionário com os parâmetros (pesos) iniciais do modelo:\n",
    "                    W1 -- weight matrix of shape (n_h, n_x)\n",
    "                    b1 -- bias vector of shape (n_h, 1)\n",
    "                    W2 -- weight matrix of shape (n_y, n_h)\n",
    "                    b2 -- bias vector of shape (n_y, 1)\n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "    W1 = np.random.uniform(low = -1/np.sqrt(n_h), high = 1/np.sqrt(n_h), size = (n_h, n_x))\n",
    "    #W1 = np.random.uniform(low = -1/np.sqrt(n_h), high = 1/np.sqrt(n_h), size = (n_h, n_x)) * 0.01\n",
    "    #b1 = np.zeros((n_h, 1))\n",
    "    b1 = np.random.uniform(low = -1/np.sqrt(n_h), high = 1/np.sqrt(n_h),size = (n_h, 1))\n",
    "    W2 = np.random.uniform(low = -1/np.sqrt(n_y), high = 1/np.sqrt(n_y),size = (n_y, n_h))\n",
    "    #b2 = np.zeros((n_y, 1))\n",
    "    b2 = np.random.uniform(low = -1/np.sqrt(n_y), high = 1/np.sqrt(n_y),size = (n_y, 1))\n",
    "    \n",
    "    \n",
    "    assert (W1.shape == (n_h, n_x))\n",
    "    assert (b1.shape == (n_h, 1))\n",
    "    assert (W2.shape == (n_y, n_h))\n",
    "    assert (b2.shape == (n_y, 1))\n",
    "    \n",
    "    parameters = {\"W1\": W1,\n",
    "                  \"b1\": b1,\n",
    "                  \"W2\": W2,\n",
    "                  \"b2\": b2}\n",
    "    \n",
    "    return parameters\n",
    "\n",
    "def forward_propagation2(X, parameters):\n",
    "    \"\"\"\n",
    "    Argumentos:\n",
    "    X -- input de tamanho (n_x, m)\n",
    "    parametros -- python dicionário contendo os parâmetros (saída da função de inicialização dos parametros)\n",
    "    \n",
    "    Retorna:\n",
    "    A2 -- A saída da função sigmoidal ou tangente hiberbólica ou relu\n",
    "    cache -- dicionário contendo \"Z1\", \"A1\", \"Z2\" e \"A2\"\n",
    "    \"\"\"\n",
    "\n",
    "    # Recupere cada parâmetro do dicionário parameters\n",
    "    W1 = parameters['W1']\n",
    "    b1 = parameters['b1']\n",
    "    W2 = parameters['W2']\n",
    "    b2 = parameters['b2']\n",
    "    \n",
    "    # Implementando a Forward Propagation para calcular A1 tanh e A2 linear\n",
    "    Z1 = np.dot(W1,X) + b1\n",
    "    #A1 = np.tanh(Z1)\n",
    "    A1 = Z1 # linear\n",
    "    Z2 = np.dot(W2, A1) + b2\n",
    "    A2 = 1.7159*np.tanh(2/3 * Z2)\n",
    "    \n",
    "    assert(A2.shape == (1, X.shape[1]))\n",
    "    \n",
    "    cache = {\"Z1\": Z1,\n",
    "             \"A1\": A1,\n",
    "             \"Z2\": Z2,\n",
    "             \"A2\": A2}\n",
    "    \n",
    "    return A2, cache\n",
    "\n",
    "\n",
    "def compute_cost2(A2, Y, parameters):\n",
    "    \"\"\"\n",
    "    Computa o custo dado os argumentos\n",
    "    \n",
    "    Arguments:\n",
    "    A2 -- Saída linear da segunda ativação de shape (1, qtd de exemplos)\n",
    "    Y -- Valor verdadeiro do rótulo de shape (1, qtd de exemplos)\n",
    "    parameters -- dicionário contendo os parâmetros W1, b1, W2 and b2\n",
    "    \n",
    "    Retorna:\n",
    "    cost\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    m = Y.shape[1] # quantidade de exemplos\n",
    "\n",
    "    # Computa o custo (cost)\n",
    "    err = A2 - Y\n",
    "    cost = 1/m * np.sum(err**2)\n",
    "    \n",
    "    cost = float(np.squeeze(cost))  # garanta que o custo tem a dimensão esperada\n",
    "    assert(isinstance(cost, float))\n",
    "    \n",
    "    return cost\n",
    "\n",
    "def backward_propagation2(parameters, cache, X, Y):\n",
    "    \"\"\"\n",
    "    Implementa a retropropagação \n",
    "    \n",
    "    Argumentos:\n",
    "    parameters -- dicionário contendo os parâmetros\n",
    "    cache -- dicionário contendo \"Z1\", \"A1\", \"Z2\" and \"A2\".\n",
    "    X -- input de shape (qtd de features, qtd de examplos)\n",
    "    Y -- valor verdadeiro do rótulo de shape (1, qtd de examplos)\n",
    "    \n",
    "    Retorna:\n",
    "    grads -- dicionário contendo os gradientes em relação aos diferentes parâmetros\n",
    "    \"\"\"\n",
    "    m = X.shape[1]\n",
    "    \n",
    "    # Primeiro, recuperamos W1 e W2 do dicinário \"parameters\"\n",
    "    W1 = parameters['W1']\n",
    "    W2 = parameters['W2']\n",
    "        \n",
    "    # Recuperamos também A1 e A2 do dicionário \"cache\".\n",
    "    A1 = cache['A1']\n",
    "    A2 = cache['A2']\n",
    "    Z2 = cache['Z2']\n",
    "    \n",
    "    # Retropropagação: calcula-se dW1, db1, dW2, db2.\n",
    "    dZ2 = (A2 - Y)* (2/3/1.7159 - np.tanh(2/3*Z2)**2)\n",
    "    #dZ2 = (A2 - Y)*(1.14393 - (A2**2)/1.5)\n",
    "    dW2 = 1/m * np.dot(dZ2,A1.T)\n",
    "    db2 = 1/m * np.sum(dZ2, axis = 1, keepdims=True)\n",
    "    #dZ1 = np.dot(W2.T, dZ2) * (1-np.power(A1, 2))\n",
    "    #dZ1 = np.dot(W2.T, dZ2) * A1\n",
    "    dZ1 = np.dot(W2.T, dZ2)\n",
    "    dW1 = 1/m * np.dot(dZ1, X.T)\n",
    "    db1 = 1/m * np.sum(dZ1, axis = 1, keepdims=True)\n",
    "    \n",
    "\n",
    "    grads = {\"dW1\": dW1,\n",
    "             \"db1\": db1,\n",
    "             \"dW2\": dW2,\n",
    "             \"db2\": db2}\n",
    "    \n",
    "    return grads\n",
    "\n",
    "def update_parameters2(parameters, grads, learning_rate = 1.2):\n",
    "    \"\"\"\n",
    "    Atualiza os parâmetros utilizando o gradient descendente \n",
    "    \n",
    "    Argumentos:\n",
    "    parameters -- dicionário contendo os parâmetros\n",
    "    grads -- dicionário contendo os gradientes\n",
    "    \n",
    "    Retorna:\n",
    "    parameters -- dicionário contendo os parâmetros atualizados\n",
    "    \"\"\"\n",
    "    # Recupera-se cada parâmetro do dicionário \"parameters\"\n",
    "    W1 = parameters['W1']\n",
    "    b1 = parameters['b1']\n",
    "    W2 = parameters['W2']\n",
    "    b2 = parameters['b2']\n",
    "    \n",
    "    # Recupera-se cada gradiente do dicionário \"grads\"\n",
    "    dW1 = grads['dW1']\n",
    "    db1 = grads['db1']\n",
    "    dW2 = grads['dW2']\n",
    "    db2 = grads['db2']\n",
    "    \n",
    "    # Regra de atualização para cada parâmetro\n",
    "    W1 = W1 - learning_rate * dW1\n",
    "    b1 = b1 - learning_rate * db1\n",
    "    W2 = W2 - learning_rate * dW2\n",
    "    b2 = b2 - learning_rate * db2\n",
    "    \n",
    "    parameters = {\"W1\": W1,\n",
    "                  \"b1\": b1,\n",
    "                  \"W2\": W2,\n",
    "                  \"b2\": b2}\n",
    "    \n",
    "    return parameters\n",
    "\n",
    "def nn_model2(X, Y, n_h, num_iterations = 10000, print_cost=False):\n",
    "    \"\"\"\n",
    "    Argumentos:\n",
    "    X -- dataset de shape (2, qtd de examplos)\n",
    "    Y -- labels de shape (1, qtd de examplos)\n",
    "    n_h -- tamanho da camada escondida\n",
    "    num_iterations -- quantidade de iterações do gradiente descendente\n",
    "    print_cost -- se True, mostra o custo a cada 1000 iterações\n",
    "    \n",
    "    Retorna:\n",
    "    parameters -- parâmetros aprendidos pelo modelo. Eles podem ser utilizados para fazer previsões (predict).\n",
    "    \"\"\"\n",
    "    \n",
    "    n_x = layer_sizes2(X, Y)[0]\n",
    "    n_y = layer_sizes2(X, Y)[2]\n",
    "    \n",
    "    # Inicialização dos parâmetros\n",
    "    parameters = initialize_parameters2(n_x, n_h, n_y)\n",
    "\n",
    "    # Gradiente descendente (loop)\n",
    "    for i in range(0, num_iterations):\n",
    "         \n",
    "        # Forward propagation. Inputs: \"X, parameters\". Outputs: \"A2, cache\".\n",
    "        A2, cache = forward_propagation2(X, parameters)\n",
    "        \n",
    "        # Função de custo. Inputs: \"A2, Y, parameters\". Outputs: \"cost\".\n",
    "        cost = compute_cost2(A2, Y, parameters)\n",
    " \n",
    "        # Retropropagação (Backpropagation). Inputs: \"parameters, cache, X, Y\". Outputs: \"grads\".\n",
    "        grads = backward_propagation2(parameters, cache, X, Y)\n",
    " \n",
    "        # Atualização dos parâmetros pelo gradiente descendente. Inputs: \"parameters, grads\". Outputs: \"parameters\".\n",
    "        parameters = update_parameters2(parameters, grads, learning_rate=1.2)\n",
    "        \n",
    "        # Print o custo (cost) a cada 1000 iterações\n",
    "        if print_cost and i % 1000 == 0:\n",
    "            print (\"Custo após iteração %i: %f\" %(i, cost))\n",
    "\n",
    "    return parameters\n",
    "\n",
    "def predict2(parameters, X):\n",
    "    \"\"\"\n",
    "    Utiliza os parâmetros aprendidos para prever o valor da saída para cada exemplo X \n",
    "    \n",
    "    Argumentos:\n",
    "    parameters -- dicionário contendo os parâmetros\n",
    "    X -- input de tamanho (n_x, m)\n",
    "    \n",
    "    Retorna\n",
    "    predictions -- vetor de valores previstos do modelo treinado\n",
    "    \"\"\"\n",
    "    \n",
    "    A2, cache = forward_propagation2(X, parameters)\n",
    "    predictions = A2\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Resilient Backpropagation RProp ####\n",
    "\n",
    "def rprop_update(parameter, grad_old, grad_new, step_size,learning_rate_max, learning_rate_min):\n",
    "    \n",
    "    # dimensões\n",
    "    n_i = parameter.shape[0]\n",
    "    n_j = parameter.shape[1]\n",
    "\n",
    "    # transformando em vetor\n",
    "    parameter.reshape(-1, 1)\n",
    "    grad_old.reshape(-1, 1)\n",
    "    grad_new.reshape(-1, 1)\n",
    "    step_size.reshape(-1, 1)\n",
    "\n",
    "    diffs = np.multiply(grad_old, grad_new)\n",
    "    pos_indexes = np.where(diffs > 0)\n",
    "    neg_indexes = np.where(diffs < 0)\n",
    "    zero_indexes = np.where(diffs == 0)\n",
    "\n",
    "    # positive\n",
    "    if np.any(pos_indexes):\n",
    "        # calcular o peso do step size\n",
    "        step_size[pos_indexes] = np.minimum(step_size[pos_indexes] * learning_rate_max, step_size.max())       \n",
    "        # calcular a direção do peso do step size\n",
    "        grad_new[pos_indexes] = np.multiply(-np.sign(grad_new[pos_indexes]), step_size[pos_indexes])\n",
    "\n",
    "        # calcular o novo peso do parâmetro\n",
    "        parameter[pos_indexes] += grad_new[pos_indexes]\n",
    "\n",
    "\n",
    "    if np.any(neg_indexes):\n",
    "        # calcular o peso do step size\n",
    "        step_size[neg_indexes] = np.maximum(step_size[neg_indexes] * learning_rate_min, step_size.min())\n",
    "            \n",
    "        # calcular a direção do peso \n",
    "        grad_new[neg_indexes] = 0 \n",
    "\n",
    "    if np.any(zero_indexes):\n",
    "        # calcular o peso do step size\n",
    "        grad_new[zero_indexes] = np.multiply(-np.sign(grad_new[zero_indexes]), step_size[zero_indexes])\n",
    "        parameter[zero_indexes] += grad_new[zero_indexes]\n",
    "    \n",
    "\n",
    "    parameter.reshape(n_i, n_j)\n",
    "    grad_old.reshape(n_i, n_j)\n",
    "    grad_new.reshape(n_i, n_j)\n",
    "    step_size.reshape(n_i, n_j)\n",
    "\n",
    "    return parameter, grad_new, step_size\n",
    "    \n",
    "    # for i in range(n_i):\n",
    "\n",
    "    #     for j in range(n_j):\n",
    "\n",
    "    #         if grad_old[i, j] * grad_new[i, j] > 0:\n",
    "    #             step_size[i, j] = min(step_size[i,j] * learning_rate_max, step_size.max())\n",
    "    #             grad_new[i, j] = np.sign(grad_new[i, j]) * step_size[i, j]\n",
    "    #             #grad_new[i, j] = - np.sign(grad_new[i, j]) * step_size[i, j]\n",
    "    #             #parameter[i, j] = parameter[i, j] + grad_new[i, j]\n",
    "            \n",
    "    #         elif grad_old[i, j] * grad_new[i, j] < 0:\n",
    "    #             step_size[i, j] = max(step_size[i,j] * learning_rate_min, step_size.min())\n",
    "    #             grad_new[i, j] = 0\n",
    "            \n",
    "    #         else:\n",
    "    #             grad_new[i, j] = np.sign(grad_new[i, j]) * step_size[i, j] \n",
    "    #             #grad_new[i, j] = - np.sign(grad_new[i, j]) * step_size[i, j]\n",
    "    #             #parameter[i, j] = parameter[i, j] + grad_new[i, j]\n",
    "\n",
    "    # parameter = parameter - grad_new\n",
    "\n",
    "    # return parameter, grad_new, step_size\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def update_parameters_rprop2(parameters, grads_old, grads_new, step_size,learning_rate_max = 1.2, learning_rate_min = 0.5):\n",
    "    \"\"\"\n",
    "    Atualiza os parâmetros utilizando o Resilient backpropagation\n",
    "    \n",
    "    Argumentos:\n",
    "    parameters -- dicionário contendo os parâmetros\n",
    "    grads -- dicionário contendo os gradientes\n",
    "    \n",
    "    Retorna:\n",
    "    parameters -- dicionário contendo os parâmetros atualizados\n",
    "    \"\"\"\n",
    "    # Recupera-se cada parâmetro do dicionário \"parameters\"\n",
    "    W1 = parameters['W1']\n",
    "    b1 = parameters['b1']\n",
    "    W2 = parameters['W2']\n",
    "    b2 = parameters['b2']\n",
    "    \n",
    "    # Recupera-se cada gradiente do dicionário \"grads_old\" e \"grads_new\"\n",
    "    dW1_old = grads_old['dW1']\n",
    "    db1_old = grads_old['db1']\n",
    "    dW2_old = grads_old['dW2']\n",
    "    db2_old = grads_old['db2']\n",
    "\n",
    "    dW1_new = grads_new['dW1']\n",
    "    db1_new = grads_new['db1']\n",
    "    dW2_new = grads_new['dW2']\n",
    "    db2_new = grads_new['db2']\n",
    "\n",
    "    W1_step = step_size['W1']\n",
    "    b1_step = step_size['b1']\n",
    "    W2_step = step_size['W2']\n",
    "    b2_step = step_size['b2']\n",
    "\n",
    "    W2, dW2_new, W2_step = rprop_update(W2,dW2_old, dW2_new, W2_step, learning_rate_max, learning_rate_min)\n",
    "    b2, db2_new, b2_step = rprop_update(b2,db2_old, db2_new, b2_step, learning_rate_max, learning_rate_min)\n",
    "    W1, dW1_new, W1_step = rprop_update(W1, dW1_old, dW1_new, W1_step, learning_rate_max, learning_rate_min)\n",
    "    b1, db1_new, b1_step = rprop_update(b1,db1_old, db1_new, b1_step, learning_rate_max, learning_rate_min) \n",
    "\n",
    "    parameters = {\"W1\": W1,\n",
    "                  \"b1\": b1,\n",
    "                  \"W2\": W2,\n",
    "                  \"b2\": b2}\n",
    "    \n",
    "    grads = {\"dW1\": dW1_new,\n",
    "             \"db1\": db1_new,\n",
    "             \"dW2\": dW2_new,\n",
    "             \"db2\": db2_new}\n",
    "\n",
    "    step_size = {\"W1\": W1_step,\n",
    "                 \"b1\": b1_step,\n",
    "                 \"W2\": W2_step,\n",
    "                 \"b2\": b2_step}\n",
    "\n",
    "    return parameters, grads, step_size\n",
    "\n",
    "def nn_model_rprop(X, Y, n_h, num_iterations = 10000, print_cost=False):\n",
    "    \"\"\"\n",
    "    Argumentos:\n",
    "    X -- dataset de shape (2, qtd de examplos)\n",
    "    Y -- labels de shape (1, qtd de examplos)\n",
    "    n_h -- tamanho da camada escondida\n",
    "    num_iterations -- quantidade de iterações do gradiente descendente\n",
    "    print_cost -- se True, mostra o custo a cada 1000 iterações\n",
    "    \n",
    "    Retorna:\n",
    "    parameters -- parâmetros aprendidos pelo modelo. Eles podem ser utilizados para fazer previsões (predict).\n",
    "    \"\"\"\n",
    "    \n",
    "    n_x = layer_sizes2(X, Y)[0]\n",
    "    n_y = layer_sizes2(X, Y)[2]\n",
    "    \n",
    "    # Inicialização dos parâmetros\n",
    "    parameters = initialize_parameters2(n_x, n_h, n_y)\n",
    "    \n",
    "    # Gradiente descendente (loop)\n",
    "    grads_old = {\"dW1\": np.zeros((n_h, n_x)),\n",
    "                 \"db1\": np.zeros((n_h, 1)),\n",
    "                 \"dW2\": np.zeros((n_y, n_h)),\n",
    "                 \"db2\": np.zeros((n_y, 1))}\n",
    "\n",
    "    step_size = {\"W1\": np.random.rand(n_h, n_x),\n",
    "                \"b1\": np.random.rand(n_h, 1),\n",
    "                \"W2\": np.random.rand(n_y, n_h),\n",
    "                \"b2\": np.random.rand(n_y, 1)}\n",
    "\n",
    "    for i in range(0, num_iterations):\n",
    "         \n",
    "        # Forward propagation. Inputs: \"X, parameters\". Outputs: \"A2, cache\".\n",
    "        A2, cache = forward_propagation2(X, parameters)\n",
    "        \n",
    "        # Função de custo. Inputs: \"A2, Y, parameters\". Outputs: \"cost\".\n",
    "        cost = compute_cost2(A2, Y, parameters)\n",
    " \n",
    "        # Retropropagação (Backpropagation). Inputs: \"parameters, cache, X, Y\". Outputs: \"grads\".\n",
    "        grads_new = backward_propagation2(parameters, cache, X, Y)\n",
    " \n",
    "        # Atualização dos parâmetros pelo gradiente descendente. Inputs: \"parameters, grads\". Outputs: \"parameters\".\n",
    "        parameters, grads_old, step_size = update_parameters_rprop2(parameters, grads_old, grads_new, step_size, learning_rate_max=1.2, learning_rate_min=0.5)\n",
    "\n",
    "        # Print o custo (cost) a cada 1000 iterações\n",
    "        if print_cost and i % 1000 == 0:\n",
    "            print (\"Custo após iteração %i: %f\" %(i, cost))\n",
    "\n",
    "    return parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Estruturando os dados de dicionário para numpy array e de numpy array para dicionário\n",
    "def parameter_dim_tot(parameter):\n",
    "    '''\n",
    "    Argumentos:\n",
    "    parameter - array de parâmetros\n",
    "\n",
    "    Retorna:\n",
    "    dim_tot - dimensão total dos parâmetris \n",
    "    '''\n",
    "    dim_tot = np.array(parameter.shape).prod()\n",
    "\n",
    "    return dim_tot\n",
    "\n",
    "def parameter_reshape_coluna(parameter):\n",
    "    '''\n",
    "    Argumentos:\n",
    "    parameter - array de parâmetros\n",
    "\n",
    "    Retorna:\n",
    "    parameter_reshaped - array coluna dos parâmetros\n",
    "    '''\n",
    "    param_dim_tot = parameter_dim_tot(parameter)\n",
    "    parameter_reshaped = parameter.reshape(1, param_dim_tot)\n",
    "\n",
    "    return parameter_reshaped\n",
    "\n",
    "def parameters_stack(parameters):\n",
    "    '''\n",
    "    Argumentos: \n",
    "    parameters - lista com os parâmetros em array \n",
    "\n",
    "    Retorna:\n",
    "    parametros_stack - array coluna com parâmetros empilhados\n",
    "    '''\n",
    "    params_list = []\n",
    "    param_temp = 0\n",
    "    \n",
    "    for param in parameters:\n",
    "        param_temp = parameter_reshape_coluna(param)\n",
    "        params_list.append(param_temp)\n",
    "    \n",
    "    params_stack = np.concatenate(tuple(params_list), axis = 1)\n",
    "\n",
    "    return params_stack\n",
    "\n",
    "# Unstack os parâmetros com base na dimensão dos atributos (matrizes de pesos)\n",
    "def parameters_unstack(parameters_stack, atributos_dim):\n",
    "    '''\n",
    "    Argumentos:\n",
    "    parameters_stack - array dos parâmetros no formato empilhado por colunas para trabalhar no PSO\n",
    "    atributos_dim - lista com dimensão total dos atributos \n",
    "\n",
    "    Retorna:\n",
    "    params - lista com parâmetros no formato de lista\n",
    "    '''\n",
    "    params = []\n",
    "    i = atributos_dim[0]\n",
    "    params.append(parameters_stack[:, :i])\n",
    "\n",
    "    for dim in atributos_dim[1:]:\n",
    "        params.append(parameters_stack[:, i:i+dim])\n",
    "        i += dim\n",
    "\n",
    "    return params\n",
    "\n",
    "# Reshape para o formato do dicionário (parameters)\n",
    "def parameters_reshape_dictionary(parameters_dict, parameters_unstacked):\n",
    "    '''\n",
    "    Argumentos:\n",
    "    parameters_dict - dicionário com parâmetros\n",
    "    parameters_unstacked - parâmetros no formato array \n",
    "\n",
    "    retorna:\n",
    "    parameters_reshaped - lista com os parâmetros formatados para o dicionário 'parameters'\n",
    "    '''\n",
    "    w1_shape = parameters_dict['W1'].shape\n",
    "    b1_shape = parameters_dict['b1'].shape\n",
    "    w2_shape = parameters_dict['W2'].shape\n",
    "    b2_shape = parameters_dict['b2'].shape\n",
    "\n",
    "    parameters_reshaped = parameters_dict.copy()\n",
    "\n",
    "    w1_reshaped = parameters_unstacked[0].reshape(w1_shape)\n",
    "    b1_reshaped = parameters_unstacked[1].reshape(b1_shape)\n",
    "    w2_reshaped = parameters_unstacked[2].reshape(w2_shape)\n",
    "    b2_reshaped = parameters_unstacked[3].reshape(b2_shape)\n",
    "\n",
    "    parameters_reshaped['W1'] = w1_reshaped\n",
    "    parameters_reshaped['b1'] = b1_reshaped\n",
    "    parameters_reshaped['W2'] = w2_reshaped\n",
    "    parameters_reshaped['b2'] = b2_reshaped\n",
    "\n",
    "    return parameters_reshaped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### PSO para otimizar todos os parâmetros de uma só vez \n",
    "    \n",
    "def PSO_todos(X, parameters, parameters_stacked, fun, Y, best_cost,qtd_particulas, atributos_dim, min_i, max_i, \n",
    "              max_epoch=1000, w_in=0.7, w_fim = 0.2, c1=1.496, c2=1.496):\n",
    "    '''\n",
    "        Função do Algoritmo SWARM PSO. \n",
    "        Inputs:\n",
    "        - fun_opt: Função de fitness a ser otimizada\n",
    "        - qtd_particulas: Quantidade de partículas\n",
    "        - atributos_dim: Dimensão do Vetor de atributos \n",
    "        - min: intervalo inferior do domínio da função  \n",
    "        - max: intervalo superior do domínio da função\n",
    "        - w: inércia \n",
    "        - c1: influência do pbest (termo cognitivo)\n",
    "        - c2: influência do gbest (termo do aprendizado social)\n",
    "    '''\n",
    "    \n",
    "    def weight_decay(w_in, w_fim, iter, iter_max):\n",
    "        \n",
    "        return w_in + w_fim * (1 - (iter/iter_max))\n",
    "\n",
    "\n",
    "    atributos_dim_sum = sum(atributos_dim)\n",
    "\n",
    "    # inicializar as partículas em posições aleatórias\n",
    "    particulas = np.random.uniform(low = min_i, high = max_i, size = (qtd_particulas, atributos_dim_sum))\n",
    "\n",
    "    # inicializar a velocidade\n",
    "    velocidade = np.zeros((qtd_particulas, atributos_dim_sum))\n",
    "\n",
    "    # inicializar o pbest em zero\n",
    "    pbest = np.zeros((qtd_particulas,atributos_dim_sum))\n",
    "\n",
    "    gbest_value = best_cost\n",
    "    print('Custo gbest inicio PSO = ', gbest_value)\n",
    "\n",
    "    gbest = 0\n",
    "    #particulas[gbest,:] = parameters_stacked\n",
    "    \n",
    "    parameters_gbest_dict = parameters.copy()\n",
    "    parameters_dict = parameters.copy()\n",
    "\n",
    "    # Extrair a posição do gbest \n",
    "    for z in np.arange(qtd_particulas):\n",
    "        parameters_temp = particulas[[z],:]\n",
    "        parameters_temp_unstacked = parameters_unstack(parameters_temp, atributos_dim)\n",
    "        parameters_temp_dict = parameters_reshape_dictionary(parameters_dict, parameters_temp_unstacked)\n",
    "        A2 = predict2(parameters_temp_dict, X)\n",
    "        new_value = fun(A2, Y, parameters_temp_dict)\n",
    "\n",
    "        if new_value < gbest_value:\n",
    "            gbest_value = new_value\n",
    "            gbest = z\n",
    "            parameters_gbest_dict = parameters_temp_dict\n",
    "\n",
    "    # print(parameters_gbest_dict)\n",
    "    print('gbest', gbest)\n",
    "    \n",
    "    for k in np.arange(max_epoch):\n",
    "\n",
    "        # Atualização do decaimento do peso\n",
    "        w = weight_decay(w_in, w_fim,k, max_epoch)                \n",
    "        \n",
    "    # Iterar para atualizar o pbest e gbest para cada partrícula\n",
    "        for j in np.arange(qtd_particulas):\n",
    "        \n",
    "            # transformando as partículas no formato de dicionário\n",
    "            parameters_temp = particulas[[j],:]\n",
    "            parameters_temp_unstacked = parameters_unstack(parameters_temp, atributos_dim)\n",
    "            parameters_temp_dict = parameters_reshape_dictionary(parameters_dict, parameters_temp_unstacked)\n",
    "\n",
    "            parameters_pbest_temp = pbest[[j],:]\n",
    "            parameters_pbest_temp_unstacked = parameters_unstack(parameters_pbest_temp, atributos_dim)\n",
    "            parameters_pbest_dict = parameters_reshape_dictionary(parameters_dict, parameters_temp_unstacked)\n",
    "\n",
    "            A2_part = predict2(parameters_temp_dict, X)\n",
    "            A2_pbest = predict2(parameters_pbest_dict, X)\n",
    "            \n",
    "            # pbest\n",
    "            if fun(A2_part, Y, parameters_temp_dict) < fun(A2_pbest, Y, parameters_pbest_dict):\n",
    "                pbest[j,:] = particulas[j,:]\n",
    "\n",
    "            # gbest\n",
    "            if fun(A2_part, Y, parameters_temp_dict) < gbest_value:\n",
    "                if np.abs(fun(A2_part, Y, parameters_temp_dict) - gbest_value) < 0.00001:\n",
    "                    print('Parar o algoritmo pois o gbest não melhorou')\n",
    "                    gbest_value = fun(A2_part, Y, parameters_temp_dict)\n",
    "                    gbest = j\n",
    "                    parameters_gbest_dict = parameters_temp_dict\n",
    "                    break\n",
    "                    \n",
    "                print('\\nCusto menor que Gbest na iteração ', k)\n",
    "                print('Custo = ', fun(A2_part, Y, parameters_temp_dict))\n",
    "                gbest = j\n",
    "                gbest_value = fun(A2_part, Y, parameters_temp_dict)\n",
    "                parameters_gbest_dict = parameters_temp_dict\n",
    "                                      \n",
    "         # Iteração para atualizar as posições das partículas\n",
    "        for i in np.arange(qtd_particulas):\n",
    "            r1, r2 = np.random.rand(), np.random.rand()\n",
    "            velocidade[i, :] = w * velocidade[i, :] + c1 * r1 * (pbest[i, :] - particulas[i, :]) + c2 * r2 * (particulas[gbest, :] - particulas[i, :])\n",
    "                # Atualizar partículas\n",
    "            particulas[i, :] = particulas[i, :] + velocidade[i, :]\n",
    "\n",
    "            # lidar com limites das partículas\n",
    "            for dim in np.arange(atributos_dim_sum):\n",
    "                if particulas[i, dim] < min_i:\n",
    "                    particulas[i, dim] = min_i\n",
    "                elif particulas[i, dim] > max_i:\n",
    "                    particulas[i, dim] = max_i\n",
    "\n",
    "    return parameters_gbest_dict\n",
    "\n",
    "def update_parameters_pso_todos(X, parameters, compute_cost2, Y, best_cost):\n",
    "    '''\n",
    "    Argumentos:\n",
    "    parameters - dicionário contendo os parâmetros do modelo\n",
    "    compute_cost2 - função a ser minimizada, neste caso a função de custo\n",
    "    A2 - previsão feita pelo modelo\n",
    "    Y - rótulo \n",
    "\n",
    "    Retorna:\n",
    "    parameters - parâmetros atualizados a partir do PSO\n",
    "    '''\n",
    "\n",
    "    # Extrair os parâmetros do dicionário para calcular a dimensão total e para criar o array colunas\n",
    "    W1 = parameters['W1']\n",
    "    b1 = parameters['b1']\n",
    "    W2 = parameters['W2']\n",
    "    b2 = parameters['b2']\n",
    "\n",
    "    # Extrair a dimensão total \n",
    "    W1_dim = np.array(W1.shape).prod()\n",
    "    b1_dim = np.array(b1.shape).prod()\n",
    "    W2_dim = np.array(W2.shape).prod()\n",
    "    b2_dim = np.array(b2.shape).prod()\n",
    "\n",
    "    # lista com parâmetros\n",
    "    parametros = [W1, b1, W2, b2]\n",
    "    # parâmetros no formato array colunas\n",
    "    parameters_stacked = parameters_stack(parametros)\n",
    "\n",
    "    atributos_dim = [W1_dim, b1_dim, W2_dim, b2_dim]\n",
    "\n",
    "    qtd_particulas_dim = (W1.shape[1] + 1)*W1.shape[0] + (W1.shape[0] + 1)*W2.shape[0]\n",
    "\n",
    "    parameters_pso = PSO_todos(X = X, parameters = parameters, parameters_stacked = parameters_stacked, \n",
    "                               fun = compute_cost2, Y = Y, best_cost = best_cost, qtd_particulas = qtd_particulas_dim, \n",
    "                               atributos_dim = atributos_dim, min_i = -1, max_i = 1)\n",
    "    \n",
    "    A2 = predict2(parameters_pso, X)\n",
    "    best_cost = compute_cost2(A2, Y, parameters_pso)\n",
    "    \n",
    "    print('Erro de treinamento após otimizar parâmetros = ' + str(best_cost))\n",
    "\n",
    "    return parameters_pso\n",
    "\n",
    "def nn_model_pso_todos(X, Y, n_h, num_iterations = 1, print_cost=False):\n",
    "    \"\"\"\n",
    "    Argumentos:\n",
    "    X -- dataset de shape (2, qtd de exemplos)\n",
    "    Y -- labels de shape (1, qtd de exemplos)\n",
    "    n_h -- tamanho da camada escondida\n",
    "    num_iterations -- quantidade de iterações do gradiente descendente\n",
    "    print_cost -- se True, mostra o custo a cada 1000 iterações\n",
    "    \n",
    "    Retorna:\n",
    "    parameters -- parâmetros aprendidos pelo pso. Eles podem ser utilizados para fazer previsões (predict).\n",
    "    \"\"\"\n",
    "    \n",
    "    n_x = layer_sizes2(X, Y)[0]\n",
    "    n_y = layer_sizes2(X, Y)[2]\n",
    "    \n",
    "    # Inicialização dos parâmetros\n",
    "    parameters = initialize_parameters2(n_x, n_h, n_y)\n",
    "    \n",
    "    parameters_best = parameters.copy()\n",
    "    \n",
    "    A2, _ = forward_propagation2(X, parameters)\n",
    "\n",
    "    best_cost = compute_cost2(A2, Y, parameters)\n",
    "    \n",
    "    for i in range(0, num_iterations):\n",
    " \n",
    "        # Atualização dos parâmetros pelo gradiente descendente. Inputs: \"parameters, compute_cost2, A2, Y\". Outputs: \"parameters\".\n",
    "        parameters = update_parameters_pso_todos(X, parameters, compute_cost2, Y, best_cost)\n",
    "\n",
    "        # Forward propagation. Inputs: \"X, parameters\". Outputs: \"A2, cache\".\n",
    "        A2, _ = forward_propagation2(X, parameters)\n",
    "\n",
    "        # Função de custo. Inputs: \"A2, Y, parameters\". Outputs: \"cost\".\n",
    "        cost_new = compute_cost2(A2, Y, parameters)\n",
    "\n",
    "        # Avaliar se a nova busca melhorou\n",
    "        if cost_new < best_cost:\n",
    "            parameters_best = parameters\n",
    "            best_cost = cost_new\n",
    "\n",
    "        # Print o custo (cost) a cada 5 iterações\n",
    "        if print_cost and i % 2 == 0:\n",
    "            print (\"Custo após iteração %i: %f\" %(i, cost_new))\n",
    "    \n",
    "    return parameters_best, best_cost\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Experimento com as as séries do artigo \n",
    "\n",
    "## Importar funções para pre-processar os dados\n",
    "from funcoes import split_sequence, divisao_dados_temporais, normalizar_serie, desnormalizar, cenarios_dinamicos, cmf, gf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sunspot\n",
    "\n",
    "Série anual.\n",
    "\n",
    "Inputs: 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     5.0\n",
       "1    11.0\n",
       "2    16.0\n",
       "3    23.0\n",
       "4    36.0\n",
       "Name: valor, dtype: float64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Sunspot\n",
    "sunspot = pd.read_csv('dados/sunspot.csv')\n",
    "sunspot = sunspot['valor']\n",
    "sunspot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Particao de Treinamento: 0 156\n",
      "Particao de Validacao: 156 222\n",
      "Particao de Teste: 222 279\n"
     ]
    }
   ],
   "source": [
    "sunspot_norm = normalizar_serie(sunspot)\n",
    "X, y = split_sequence(sunspot_norm.values, 10, 1)\n",
    "\n",
    "X_treino, y_treino, X_teste, y_teste, X_val, y_val = divisao_dados_temporais(X, y, perc_treino = 0.56, perc_val = 0.24)\n",
    "# para avaliar mse\n",
    "y_teste_ = desnormalizar(y_teste, sunspot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Treinar rede neural com Rprop\n",
    "\n",
    "##### Testar 5 neurônios na camada escondida e 10 execuções\n",
    "best_model = 0\n",
    "best_mse = np.inf\n",
    "\n",
    "for exec in range(1):\n",
    "    print('Execução ' + str(exec))\n",
    "    parameters = nn_model_rprop(X_treino.T, y_treino.T, n_h=5, print_cost=True)\n",
    "    y_pred = predict2(parameters, X_val.T)\n",
    "    mse_exec = compute_cost2(y_pred,y_val.T, parameters)\n",
    "    \n",
    "    if mse_exec < best_mse:\n",
    "        best_model = parameters \n",
    "        best_mse = mse_exec\n",
    "\n",
    "    print('MSE validação = ' + str(mse_exec))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Desnormalizar\n",
    "y_pred_teste = predict2(best_model, X_teste.T).reshape(-1,1)\n",
    "\n",
    "# mse de teste\n",
    "print(\"mse de teste = \",((y_pred_teste - y_teste)**2).mean())\n",
    "\n",
    "y_pred_teste = desnormalizar(y_pred_teste, sunspot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Plot\n",
    "plt.plot(y_teste_, color = 'blue')\n",
    "plt.plot(y_pred_teste, color = 'coral');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Treinar rede neural com backprop\n",
    "\n",
    "##### Testar 4 neurônios na camada escondida e 10000 epocas com 30 execuções\n",
    "best_model = 0\n",
    "best_mse = np.inf\n",
    "\n",
    "#neuronios = [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]\n",
    "neuronios = [2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "for i in neuronios:\n",
    "    print('Neurônios: ', i)\n",
    "\n",
    "    for exec in np.arange(1):\n",
    "        print('Execução ' + str(exec))\n",
    "        parameters = nn_model2(X_treino.T, y_treino.T, n_h = i, print_cost = True)\n",
    "        y_pred = predict2(parameters, X_val.T)\n",
    "        mse_exec = compute_cost2(y_pred,y_val.T, parameters)\n",
    "    \n",
    "        if mse_exec < best_mse:\n",
    "            best_model = parameters \n",
    "            best_mse = mse_exec\n",
    "            print('Melhor MSE: ', best_mse)\n",
    "            qtd_neuronios = i\n",
    "\n",
    "    \n",
    "    print('MSE validação = ' + str(mse_exec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# melhor configuração\n",
    "print('NN com {} neurônios na camada escondida'.format(qtd_neuronios))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Desnormalizar\n",
    "y_pred_teste = predict2(best_model, X_teste.T).reshape(-1,1)\n",
    "\n",
    "# mse de teste\n",
    "print(\"mse de teste = \",((y_pred_teste - y_teste)**2).mean())\n",
    "\n",
    "y_pred_teste = desnormalizar(y_pred_teste, sunspot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Plot\n",
    "plt.plot(y_teste_, label = 'Teste')\n",
    "plt.plot(y_pred_teste, color = 'coral', label = 'NN com Backprop')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Treinar rede neural com pso\n",
    "\n",
    "##### Testar 5 neurônios na camada escondida\n",
    "best_model = 0\n",
    "best_mse = np.inf\n",
    "\n",
    "neuronios = [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]\n",
    "#neuronios = [2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "for i in neuronios:\n",
    "    print('Neurônios: ', i)\n",
    "\n",
    "    for exec in np.arange(1):\n",
    "\n",
    "        print('Execução ' + str(exec))\n",
    "        parameters,_ = nn_model_pso_todos(X_treino.T, y_treino.T, n_h = i, print_cost = True)\n",
    "    \n",
    "        y_pred = predict2(parameters, X_val.T)\n",
    "        mse_exec = compute_cost2(y_pred, y_val.T,parameters)\n",
    "    \n",
    "        if mse_exec < best_mse:\n",
    "            best_model = parameters \n",
    "            \n",
    "            best_mse = mse_exec\n",
    "            print('Melhor MSE: ', best_mse)\n",
    "            qtd_neuronios = i\n",
    "\n",
    "        print('Neurônios' + str(i) + ' -> MSE validação = ' + str(mse_exec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('NN com {} neurônios na camada escondida'.format(qtd_neuronios))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Desnormalizar\n",
    "y_pred_teste = predict2(best_model, X_teste.T).reshape(-1,1)\n",
    "\n",
    "# mse de teste\n",
    "print(\"mse de teste = \",((y_pred_teste - y_teste)**2).mean())\n",
    "\n",
    "y_pred_teste = desnormalizar(y_pred_teste, sunspot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot\n",
    "plt.plot(y_teste_, label = 'Teste')\n",
    "plt.plot(y_pred_teste, label='NN com PSO')\n",
    "#plt.plot(y_teste_, color = 'blue', legend = 'Teste')\n",
    "#plt.plot(y_pred_teste, color = 'coral', legend = 'NN com PSO')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Só previsão\n",
    "plt.plot(y_pred_teste, color = 'coral',label = 'NN com PSO')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cenário I - Sunspot\n",
    "\n",
    "1. Testando Cenário I\n",
    "\n",
    "* w = 60\n",
    "* s = 10\n",
    "* f = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1445.0\n"
     ]
    }
   ],
   "source": [
    "# Quantidade total de iterações para o primeiro cenário\n",
    "\n",
    "# Seed\n",
    "np.random.seed(3)\n",
    "\n",
    "w = 60 # tamanho da janela\n",
    "s = 10 # tamanho do passo\n",
    "f = 50 # quantidade de iterações para a janela\n",
    "T = f/s*(len(y))+f\n",
    "print(T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Backprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execução:  0\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0001117492914053535\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0002843720310196415\n",
      "Melhor MSE:  0.00013305057423978963\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.00084663373021674\n",
      "Melhor MSE:  0.0004939651936896806\n",
      "Melhor MSE:  0.00044687912802225595\n",
      "Melhor MSE:  0.00040798890879363645\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0019439145800579935\n",
      "Melhor MSE:  0.0009936327311109987\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0012215441633468594\n",
      "Melhor MSE:  0.000640561549512165\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0006069358770667045\n",
      "Melhor MSE:  0.00030958863721568486\n",
      "Melhor MSE:  9.335982124589969e-05\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0004989184272657776\n",
      "Melhor MSE:  0.00041228445719923725\n",
      "Melhor MSE:  0.0003206539120497675\n",
      "Melhor MSE:  0.00020463898964974766\n",
      "Melhor MSE:  8.820689092762049e-05\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0010696425923048495\n",
      "Melhor MSE:  0.00016424625348358292\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  3.0581396554112246\n",
      "Melhor MSE:  0.0009014805400767328\n",
      "Melhor MSE:  0.0003985633760199692\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.004429272622040419\n",
      "Melhor MSE:  0.0015779189577323927\n",
      "Melhor MSE:  0.0007591943191772936\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0019565958143401493\n",
      "Melhor MSE:  0.0007337698060191834\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.000898777527143854\n",
      "Melhor MSE:  0.000485351130281606\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0011787217402568545\n",
      "Melhor MSE:  0.001071676182873731\n",
      "Melhor MSE:  0.0007758422150300964\n",
      "Melhor MSE:  0.00010009861711180544\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.000857842631765994\n",
      "Melhor MSE:  0.0005852099815823569\n",
      "Melhor MSE:  0.00020936475814189233\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0010840498782782944\n",
      "Melhor MSE:  0.00027882737300393925\n",
      "Melhor MSE:  0.0002557889605309326\n",
      "Melhor MSE:  5.997895781110962e-05\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0029643231549593596\n",
      "Melhor MSE:  0.0009783108579917705\n",
      "Melhor MSE:  0.00016416987753538104\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0006990836782729494\n",
      "Melhor MSE:  0.00030615691011934894\n",
      "Melhor MSE:  0.00022654911904245714\n",
      "Melhor MSE:  0.0001231468655356505\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0002366500887054462\n",
      "Melhor MSE:  0.0001629738797866048\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.00039985058189162244\n",
      "Melhor MSE:  0.00012047876319266085\n",
      "Melhor MSE:  9.825521305105079e-05\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0011048979082852912\n",
      "Melhor MSE:  0.00041574287466134284\n",
      "Melhor MSE:  0.0001424355057992463\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.006519925178647747\n",
      "Melhor MSE:  0.0020969720066453534\n",
      "Melhor MSE:  0.001558769361167055\n",
      "Melhor MSE:  0.0010009280949858136\n",
      "Melhor MSE:  0.000801862872979856\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.008845834701129965\n",
      "Melhor MSE:  0.003586632608282829\n",
      "Melhor MSE:  0.0034428032512856745\n",
      "Melhor MSE:  0.0018168267855074665\n",
      "Execução:  1\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0003423241479803292\n",
      "Melhor MSE:  0.00014269427304459094\n",
      "Melhor MSE:  0.0001222386905953113\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  6.474928800611261e-05\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.00048380854912507713\n",
      "Melhor MSE:  0.00017026150838101407\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0015726390624437323\n",
      "Melhor MSE:  0.0006665541640684661\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0010965686240612855\n",
      "Melhor MSE:  0.0008874141898228109\n",
      "Melhor MSE:  0.0006313405100348361\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.001723077378285397\n",
      "Melhor MSE:  0.0014827455250783896\n",
      "Melhor MSE:  0.0008269072594174064\n",
      "Melhor MSE:  0.0007770294977610568\n",
      "Melhor MSE:  0.0005328690082838449\n",
      "Melhor MSE:  0.0003116144508252968\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.00013309225774148654\n",
      "Melhor MSE:  4.609001262623526e-05\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0003469841207800247\n",
      "Melhor MSE:  9.572332717442639e-05\n",
      "Melhor MSE:  5.46040596209419e-05\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0003768408242159147\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0007690651222861746\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.00011675709860315598\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0007858759567719829\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0006208961014693481\n",
      "Melhor MSE:  0.00039773827209842075\n",
      "Melhor MSE:  0.00036775175570571516\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.000286720075602968\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0001533353425195032\n",
      "Melhor MSE:  0.0001374945593293717\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0013902757679591985\n",
      "Melhor MSE:  0.000271820901970762\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0003345729102045181\n",
      "Melhor MSE:  0.00011245667537331402\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  8.685311256944533e-05\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0008213870500140335\n",
      "Melhor MSE:  0.0004502173441072813\n",
      "Melhor MSE:  0.00022142272499661427\n",
      "Melhor MSE:  0.00020316134770455248\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0006034504129781222\n",
      "Melhor MSE:  0.0005376454565112516\n",
      "Melhor MSE:  0.0005155750221273761\n",
      "Melhor MSE:  0.0003475675309371326\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0011421180076036455\n",
      "Melhor MSE:  0.001076956823250118\n",
      "Melhor MSE:  0.00035850766259813585\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.007998936462572504\n",
      "Melhor MSE:  0.005390196386018237\n",
      "Melhor MSE:  0.0022613178772866497\n",
      "Melhor MSE:  0.001963370851216553\n",
      "Melhor MSE:  0.00096423178251854\n",
      "Execução:  2\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.00037045128332695304\n",
      "Melhor MSE:  0.0003545984578755549\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.00045763211589891094\n",
      "Melhor MSE:  0.0002438244815612893\n",
      "Melhor MSE:  0.00024056594435486399\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.00033873309389396094\n",
      "Melhor MSE:  0.0003034857325666474\n",
      "Melhor MSE:  0.0003023147546119455\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0009213420690637267\n",
      "Melhor MSE:  0.0008580082452286455\n",
      "Melhor MSE:  0.0005365501494141026\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0011379625772939257\n",
      "Melhor MSE:  0.0006694062485984551\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0006763932887590805\n",
      "Melhor MSE:  0.0006270609665805157\n",
      "Melhor MSE:  0.0004890086617211825\n",
      "Melhor MSE:  0.0003973448888238736\n",
      "Melhor MSE:  0.00023340600007338525\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.004365726153176301\n",
      "Melhor MSE:  0.003355894630850826\n",
      "Melhor MSE:  0.0003372607558279288\n",
      "Melhor MSE:  0.00031361228668388714\n",
      "Melhor MSE:  0.0002828833719609346\n",
      "Melhor MSE:  0.00020115154504095\n",
      "Melhor MSE:  9.932411318211906e-05\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.00021630283324134626\n",
      "Melhor MSE:  0.00020331859782076372\n",
      "Melhor MSE:  0.00017214116944996567\n",
      "Melhor MSE:  3.9329196802862095e-05\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0005641904777095717\n",
      "Melhor MSE:  0.000437434779805855\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0020636663527485795\n",
      "Melhor MSE:  0.001627760219228239\n",
      "Melhor MSE:  0.001487787869679661\n",
      "Melhor MSE:  0.0006780483834860291\n",
      "Melhor MSE:  0.0005846618082905503\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0017496696432523259\n",
      "Melhor MSE:  0.00067849521321264\n",
      "Melhor MSE:  0.00022163019835906415\n",
      "Melhor MSE:  0.0002178893297613081\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0006090344582744145\n",
      "Melhor MSE:  0.0003698011091072307\n",
      "Melhor MSE:  0.00023688076241923018\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.001038627369519553\n",
      "Melhor MSE:  0.0004284685365017654\n",
      "Melhor MSE:  0.00032079569272506017\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.00022701411524913496\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0011715121051667906\n",
      "Melhor MSE:  0.0002461681574480204\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0006194846844377705\n",
      "Melhor MSE:  0.00024117460618978766\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.00026302146521484717\n",
      "Melhor MSE:  8.537792381103373e-05\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0002576996123452035\n",
      "Melhor MSE:  0.00021321594651725623\n",
      "Melhor MSE:  0.0001982695842397668\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0003476897546099082\n",
      "Melhor MSE:  0.0003153080828798019\n",
      "Melhor MSE:  0.00022421437038116525\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  2.855945439479468\n",
      "Melhor MSE:  0.0011623585583287604\n",
      "Melhor MSE:  0.00101900506283548\n",
      "Melhor MSE:  0.0006399199182610928\n",
      "Melhor MSE:  0.00027202079273148613\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  2.8888967039758473\n",
      "Melhor MSE:  0.0005966798639328282\n",
      "Melhor MSE:  0.00022419067512949312\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.002397212225582484\n",
      "Melhor MSE:  0.0010027518926210071\n",
      "Execução:  3\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0004948104759425003\n",
      "Melhor MSE:  0.00037139543913905146\n",
      "Melhor MSE:  0.0002454746961059403\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.00018686241836519957\n",
      "Melhor MSE:  8.568702369656154e-05\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0005570245293142558\n",
      "Melhor MSE:  0.00020042046787544033\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  3.0267253762654662\n",
      "Melhor MSE:  0.001154512666634869\n",
      "Melhor MSE:  0.000936665157087666\n",
      "Melhor MSE:  0.0002877100737561264\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.004908415222548558\n",
      "Melhor MSE:  0.001751793863435855\n",
      "Melhor MSE:  0.0014680958145512318\n",
      "Melhor MSE:  0.0008349418334021074\n",
      "Melhor MSE:  0.0004169313162053929\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  3.087805128705048\n",
      "Melhor MSE:  2.8044221262927267\n",
      "Melhor MSE:  0.007689744505626668\n",
      "Melhor MSE:  0.0003583030725717456\n",
      "Melhor MSE:  0.00032335230822098287\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0011270812756118574\n",
      "Melhor MSE:  0.0003254253074433519\n",
      "Melhor MSE:  0.0003229163172329765\n",
      "Melhor MSE:  8.298704051066103e-05\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.00012562044724334762\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.00023391384029095916\n",
      "Melhor MSE:  0.00022254549486505097\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0011120681411212665\n",
      "Melhor MSE:  0.0010302136119203606\n",
      "Melhor MSE:  0.0007092191067792008\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0016836614887580218\n",
      "Melhor MSE:  0.0015203756165319212\n",
      "Melhor MSE:  0.0009350328817855384\n",
      "Melhor MSE:  0.0005921467050775469\n",
      "Melhor MSE:  0.00045888151266324585\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.000327840979272239\n",
      "Melhor MSE:  0.00025098379960999533\n",
      "Melhor MSE:  0.0002139266920892863\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0005124538060403593\n",
      "Melhor MSE:  0.0004927455784921091\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.001185373683983875\n",
      "Melhor MSE:  0.0008142902906734807\n",
      "Melhor MSE:  0.0006823593623621664\n",
      "Melhor MSE:  0.0002551977517899101\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0006431199224388328\n",
      "Melhor MSE:  0.00044646554830168173\n",
      "Melhor MSE:  0.00040133208180202995\n",
      "Melhor MSE:  0.00018727533962374385\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0007526013604512729\n",
      "Melhor MSE:  0.00039706757234289364\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0003561512087473821\n",
      "Melhor MSE:  0.000333763211486951\n",
      "Melhor MSE:  0.00029272028036446814\n",
      "Melhor MSE:  0.00017148954899917144\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  2.8306594713834223\n",
      "Melhor MSE:  0.0009053905565318428\n",
      "Melhor MSE:  0.0005343817568485434\n",
      "Melhor MSE:  0.00031969724793089876\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0012290055129282058\n",
      "Melhor MSE:  0.0005837799964153707\n",
      "Melhor MSE:  4.3890915847948506e-05\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0012666541723065214\n",
      "Melhor MSE:  0.0012567248741811967\n",
      "Melhor MSE:  0.000675701280009446\n",
      "Melhor MSE:  0.000637180811430277\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  2.8888967039758473\n",
      "Melhor MSE:  0.0054118371419685785\n",
      "Melhor MSE:  0.0006058503518999241\n",
      "Melhor MSE:  0.0005412189445744075\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.003601465956367374\n",
      "Melhor MSE:  0.003477837750909117\n",
      "Melhor MSE:  0.0006798975360978112\n",
      "Melhor MSE:  0.0006538996253938209\n",
      "Execução:  4\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.00024827761067758693\n",
      "Melhor MSE:  5.870357085476271e-05\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0001235862831104344\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.00025631526152491085\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0008660326118074619\n",
      "Melhor MSE:  0.0007651053312307544\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.002351430083404\n",
      "Melhor MSE:  0.0012550260488701681\n",
      "Melhor MSE:  0.0003911097137277131\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0016475944533447444\n",
      "Melhor MSE:  0.0010854360875013338\n",
      "Melhor MSE:  0.0005428781041206572\n",
      "Melhor MSE:  7.527583109685763e-05\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0003285347853844952\n",
      "Melhor MSE:  7.376771623146757e-05\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.000587597736835798\n",
      "Melhor MSE:  0.00017037827312729089\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0006614806945971849\n",
      "Melhor MSE:  0.0005625273564000463\n",
      "Melhor MSE:  0.0004533961289047412\n",
      "Melhor MSE:  0.00036710368034061287\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0016919254859786952\n",
      "Melhor MSE:  0.0008119024438634128\n",
      "Melhor MSE:  0.0006790739019905634\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.00397922672554661\n",
      "Melhor MSE:  0.00045696642901598886\n",
      "Melhor MSE:  0.00045070342148715377\n",
      "Melhor MSE:  0.00031051954544345363\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.00023103878235395536\n",
      "Melhor MSE:  0.00022069046848959155\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0001571552697063506\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0003160923377119877\n",
      "Melhor MSE:  0.0002314598583074496\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0005363410705361345\n",
      "Melhor MSE:  0.00039190977653610437\n",
      "Melhor MSE:  0.00036220799403349297\n",
      "Melhor MSE:  8.756852399007693e-05\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.00016169640942031868\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0009848358220905548\n",
      "Melhor MSE:  0.0001356927288701782\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0003859770481089739\n",
      "Melhor MSE:  0.0002273653201741973\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0006145375658938792\n",
      "Melhor MSE:  0.0005834605654727543\n",
      "Melhor MSE:  0.0002805201562517781\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.001303489574089994\n",
      "Melhor MSE:  0.0011788971076342127\n",
      "Melhor MSE:  0.0011231917570648624\n",
      "Melhor MSE:  0.0010983369265220033\n",
      "Melhor MSE:  0.0008012109173332585\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.001180100728292343\n",
      "Melhor MSE:  0.00048289819036066646\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.002279813691249693\n",
      "Melhor MSE:  0.001344328210546532\n",
      "Melhor MSE:  0.0005163794542637944\n",
      "Execução:  5\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0004987003918840421\n",
      "Melhor MSE:  0.00011799368842388592\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0008212726407910541\n",
      "Melhor MSE:  0.00022475777824384463\n",
      "Melhor MSE:  7.019809289536834e-05\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0010380196020673433\n",
      "Melhor MSE:  0.000302438144654001\n",
      "Melhor MSE:  0.0002990490788681133\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.00037178007121212\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.004641406122508795\n",
      "Melhor MSE:  0.001897443812886227\n",
      "Melhor MSE:  0.0015918745479414325\n",
      "Melhor MSE:  0.001086141831995979\n",
      "Melhor MSE:  0.0008080382189292782\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0027146444168189713\n",
      "Melhor MSE:  0.0010206649607316246\n",
      "Melhor MSE:  0.000364967753524892\n",
      "Melhor MSE:  0.00016185900781335466\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.00022308344579021757\n",
      "Melhor MSE:  0.00018077717456921699\n",
      "Melhor MSE:  6.967847291047735e-05\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0003713548280466582\n",
      "Melhor MSE:  0.00020150290117607538\n",
      "Melhor MSE:  0.0001559972682686466\n",
      "Melhor MSE:  7.02883347836099e-05\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0005609985440085401\n",
      "Melhor MSE:  0.000422163756896219\n",
      "Melhor MSE:  0.0003854714799700657\n",
      "Melhor MSE:  0.0003575011615560024\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.001130012605976046\n",
      "Melhor MSE:  0.0005584305438980186\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0007763449002571479\n",
      "Melhor MSE:  0.0004309668149103718\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0005533520581965406\n",
      "Melhor MSE:  0.0001973538526230483\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0013772896751989595\n",
      "Melhor MSE:  0.000493403698410775\n",
      "Melhor MSE:  0.00026160616838905054\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0014600361232990316\n",
      "Melhor MSE:  0.0007481137921042392\n",
      "Melhor MSE:  0.00023012005209097414\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0015519725248931214\n",
      "Melhor MSE:  0.0005659964115722704\n",
      "Melhor MSE:  0.0002121885834933907\n",
      "Melhor MSE:  9.962155138752375e-05\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0012197612134654172\n",
      "Melhor MSE:  0.0006692636883999398\n",
      "Melhor MSE:  0.00026998891963156744\n",
      "Melhor MSE:  0.000184275805283307\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0008295220119843162\n",
      "Melhor MSE:  0.000447644528216328\n",
      "Melhor MSE:  0.00033320480563082234\n",
      "Melhor MSE:  0.0002758324072441493\n",
      "Melhor MSE:  0.00018949542177735203\n",
      "Melhor MSE:  0.00017961846420563814\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0005980670049085765\n",
      "Melhor MSE:  0.00029342568257856576\n",
      "Melhor MSE:  0.0002643296851709482\n",
      "Melhor MSE:  0.0002270881682426571\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.00016126104866539086\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0005932330296260809\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.004332356739998391\n",
      "Melhor MSE:  0.0012209520106760362\n",
      "Melhor MSE:  0.0010250888979641043\n",
      "Melhor MSE:  0.001007663093496567\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.003341609193441905\n",
      "Melhor MSE:  0.0012314505076071265\n",
      "Melhor MSE:  0.0011738077195017804\n",
      "Melhor MSE:  0.0005862464365285398\n",
      "Execução:  6\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.00020471444893851485\n",
      "Melhor MSE:  0.00012843232713104753\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0004044115075824475\n",
      "Melhor MSE:  0.00013115990819010634\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0008650827540254696\n",
      "Melhor MSE:  0.0003091401988035436\n",
      "Melhor MSE:  0.0002751040913781699\n",
      "Melhor MSE:  0.00027119984112127063\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.00149102442424947\n",
      "Melhor MSE:  0.0011894903192269837\n",
      "Melhor MSE:  0.0005434522135943608\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0021891486140174776\n",
      "Melhor MSE:  0.0020496217675280925\n",
      "Melhor MSE:  0.0011188254482498946\n",
      "Melhor MSE:  0.0010994831059822027\n",
      "Melhor MSE:  0.0010889445289447787\n",
      "Melhor MSE:  0.0009154273186682004\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.00046266420143060505\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0005791796988896614\n",
      "Melhor MSE:  0.0005708352497243205\n",
      "Melhor MSE:  0.000449614538278302\n",
      "Melhor MSE:  0.00014941332575826342\n",
      "Melhor MSE:  6.483455767713996e-05\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0003332712480293484\n",
      "Melhor MSE:  0.00021326023800934102\n",
      "Melhor MSE:  0.00019506341686967887\n",
      "Melhor MSE:  0.000141457682604851\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.001411969127880898\n",
      "Melhor MSE:  0.0006776068778539632\n",
      "Melhor MSE:  0.0006276418950203889\n",
      "Melhor MSE:  0.0003707308590584071\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0013880544244803993\n",
      "Melhor MSE:  0.0007246386135566125\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0012038134034017287\n",
      "Melhor MSE:  0.0006398801361506994\n",
      "Melhor MSE:  0.00039550217986842305\n",
      "Melhor MSE:  0.00032980341504854917\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0020106840691994795\n",
      "Melhor MSE:  0.0005163524061193981\n",
      "Melhor MSE:  0.00017175428729328094\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  3.0340583048274867\n",
      "Melhor MSE:  0.0014598131615096896\n",
      "Melhor MSE:  0.0005179756773278842\n",
      "Melhor MSE:  0.00029443645758315965\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.000705934807347554\n",
      "Melhor MSE:  0.0003998209951730916\n",
      "Melhor MSE:  0.00021099750268820724\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.001553942394489267\n",
      "Melhor MSE:  0.00032378687306374305\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0007308505565638057\n",
      "Melhor MSE:  0.00030499338275202705\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.00028593655569654925\n",
      "Melhor MSE:  0.00017067826767075566\n",
      "Melhor MSE:  9.495975133434974e-05\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.001932297828730911\n",
      "Melhor MSE:  0.0005892580702542674\n",
      "Melhor MSE:  0.0003448925238012473\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.00016157155057548158\n",
      "Melhor MSE:  0.00010195474681183458\n",
      "Melhor MSE:  9.445614014084479e-05\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0008566130019344886\n",
      "Melhor MSE:  0.0004836073591563569\n",
      "Melhor MSE:  0.0001341391127764694\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0013637787802542654\n",
      "Melhor MSE:  0.0007447980464564994\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  2.9013440195960376\n",
      "Melhor MSE:  0.0021270641537927382\n",
      "Melhor MSE:  0.0016189939908121003\n",
      "Melhor MSE:  0.0009882825334054945\n",
      "Execução:  7\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.00024042077727476157\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0006267014138224112\n",
      "Melhor MSE:  0.00034850396923250465\n",
      "Melhor MSE:  0.0003216829675383258\n",
      "Melhor MSE:  0.00011985803201588982\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0021557509240163223\n",
      "Melhor MSE:  0.00034988550649321946\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  3.0267253762654662\n",
      "Melhor MSE:  2.864488986441399\n",
      "Melhor MSE:  0.0010005362072821463\n",
      "Melhor MSE:  0.0007184178828563634\n",
      "Melhor MSE:  0.0005352323643494924\n",
      "Melhor MSE:  0.0005294683509235464\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  2.8743354748151786\n",
      "Melhor MSE:  0.001969106936649997\n",
      "Melhor MSE:  0.001341878327000799\n",
      "Melhor MSE:  0.0011869232350061527\n",
      "Melhor MSE:  0.0010899922841085896\n",
      "Melhor MSE:  0.000576369055737514\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0005423421054270537\n",
      "Melhor MSE:  0.0003086773881377367\n",
      "Melhor MSE:  9.41612907198013e-05\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  3.103623548907296\n",
      "Melhor MSE:  2.789430794707824\n",
      "Melhor MSE:  0.0008209997858783732\n",
      "Melhor MSE:  0.00024474424083085203\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0005508801288846159\n",
      "Melhor MSE:  0.0005432824553739162\n",
      "Melhor MSE:  0.00040945627289688943\n",
      "Melhor MSE:  0.000296832525401245\n",
      "Melhor MSE:  0.0002343922754504608\n",
      "Melhor MSE:  0.0001242580060349001\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  2.833404349806333\n",
      "Melhor MSE:  0.0012466326941550057\n",
      "Melhor MSE:  0.0008933418845589508\n",
      "Melhor MSE:  0.0005141561261493692\n",
      "Melhor MSE:  0.0003104363462563215\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0018255750374255642\n",
      "Melhor MSE:  0.0013063357026393487\n",
      "Melhor MSE:  0.0005807640375609929\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.00585307215670126\n",
      "Melhor MSE:  0.0019756259166841986\n",
      "Melhor MSE:  0.0005937463346341757\n",
      "Melhor MSE:  0.0003161620969005866\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  6.339163865358698e-05\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.00024283660589368837\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0004258160514499842\n",
      "Melhor MSE:  0.00037880615779807027\n",
      "Melhor MSE:  0.00013012674928688194\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.00018290235279870085\n",
      "Melhor MSE:  0.0001572973623883742\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.00013499510257923916\n",
      "Melhor MSE:  0.0001163027886532039\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.00044762557540427484\n",
      "Melhor MSE:  0.0002627032802071573\n",
      "Melhor MSE:  0.00013754608525832828\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0005399624116142794\n",
      "Melhor MSE:  0.0002613227676540141\n",
      "Melhor MSE:  0.00013007928695189217\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.00025883935378911266\n",
      "Melhor MSE:  4.796812345077244e-05\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.00039303539551795136\n",
      "Melhor MSE:  0.0003086671591907352\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.010410678087152264\n",
      "Melhor MSE:  0.0016681893596890158\n",
      "Melhor MSE:  0.0005093599504191074\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.004762613542406878\n",
      "Melhor MSE:  0.0016690886159921692\n",
      "Melhor MSE:  0.0011769964360497246\n",
      "Execução:  8\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0023303867782121105\n",
      "Melhor MSE:  0.0007212572481008158\n",
      "Melhor MSE:  0.0003966950593702465\n",
      "Melhor MSE:  0.0002340420846567339\n",
      "Melhor MSE:  8.139908520857148e-05\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0008923583690213194\n",
      "Melhor MSE:  0.00029031538710266825\n",
      "Melhor MSE:  0.00023607847494908318\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  3.046031672531977\n",
      "Melhor MSE:  0.00013924019691146923\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0021082504275637907\n",
      "Melhor MSE:  0.0009190118391337923\n",
      "Melhor MSE:  0.0007051559744527226\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0038465821820546143\n",
      "Melhor MSE:  0.0011672290022918842\n",
      "Melhor MSE:  0.0009044625602107205\n",
      "Melhor MSE:  0.0004080439523043286\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0006470257520095384\n",
      "Melhor MSE:  0.00023640634121422938\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0036609997761933594\n",
      "Melhor MSE:  0.003629251257128338\n",
      "Melhor MSE:  0.000423368829662802\n",
      "Melhor MSE:  0.00033533488482784555\n",
      "Melhor MSE:  0.0003344479647354802\n",
      "Melhor MSE:  0.0002594498792075375\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.002135376111553513\n",
      "Melhor MSE:  0.00021221124947273201\n",
      "Melhor MSE:  0.00013154661968724953\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0003365464455391744\n",
      "Melhor MSE:  0.0003300758274600757\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0009939014164725467\n",
      "Melhor MSE:  0.0004706764283763558\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0005664615702052989\n",
      "Melhor MSE:  0.00040898146801471595\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0005260704773746649\n",
      "Melhor MSE:  0.00035027862580235155\n",
      "Melhor MSE:  0.00034336902286472416\n",
      "Melhor MSE:  0.0002497424049587048\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0002220235389261449\n",
      "Melhor MSE:  0.00018966187237575506\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.00034379015770158596\n",
      "Melhor MSE:  0.0002592589846855136\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0001232225745449294\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0007604954943899354\n",
      "Melhor MSE:  0.0005917648017300829\n",
      "Melhor MSE:  0.0002691306231822591\n",
      "Melhor MSE:  0.0001577633697377884\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0006914467581215925\n",
      "Melhor MSE:  0.0004604804422266446\n",
      "Melhor MSE:  0.0003478002207166983\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0006099844887025021\n",
      "Melhor MSE:  0.00016218164187320344\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.000931428969390118\n",
      "Melhor MSE:  0.0002961611702676458\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0009188875065380162\n",
      "Melhor MSE:  0.00046181090910669894\n",
      "Melhor MSE:  0.0001724593723592754\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0021228625505248983\n",
      "Melhor MSE:  0.0016737835635504891\n",
      "Melhor MSE:  0.001246193289435952\n",
      "Melhor MSE:  0.0008778938551664041\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  2.9013440195960376\n",
      "Melhor MSE:  0.002618703382643769\n",
      "Melhor MSE:  0.002362827211848844\n",
      "Melhor MSE:  0.0004709086626543409\n",
      "Execução:  9\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0004476567697271743\n",
      "Melhor MSE:  0.0004378566166946859\n",
      "Melhor MSE:  0.00029963206699432185\n",
      "Melhor MSE:  0.00016797603020620802\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0003478355073811091\n",
      "Melhor MSE:  0.00020891711790113827\n",
      "Melhor MSE:  0.00019431292782083555\n",
      "Melhor MSE:  0.000154612663915039\n",
      "Melhor MSE:  9.792388873032167e-05\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.00030617552786212776\n",
      "Melhor MSE:  0.00022807079538106546\n",
      "Melhor MSE:  0.00010074494690294326\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0018085589345427022\n",
      "Melhor MSE:  0.0015847988381088817\n",
      "Melhor MSE:  0.001301798443210502\n",
      "Melhor MSE:  0.0010430450851147796\n",
      "Melhor MSE:  0.0008017100960269704\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0006790455788566028\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.003068997051291155\n",
      "Melhor MSE:  0.0015306328906418527\n",
      "Melhor MSE:  0.0013072050328940847\n",
      "Melhor MSE:  0.00044202793411372957\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0011876876538487585\n",
      "Melhor MSE:  0.0009356702322609216\n",
      "Melhor MSE:  0.000734741486479602\n",
      "Melhor MSE:  0.0005166819392401915\n",
      "Melhor MSE:  0.00048669538824197415\n",
      "Melhor MSE:  0.00031620561364765023\n",
      "Melhor MSE:  0.00012162828540135558\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0009066270626622623\n",
      "Melhor MSE:  0.0003029620486324043\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0005354986628532065\n",
      "Melhor MSE:  0.00033169063510209737\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0010539885253685384\n",
      "Melhor MSE:  0.0008282098588202826\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0021047255277485554\n",
      "Melhor MSE:  0.0002416021802852044\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0003119616278527316\n",
      "Melhor MSE:  0.0002897366923282396\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.003296821063556713\n",
      "Melhor MSE:  0.00041956037220297897\n",
      "Melhor MSE:  0.00038269435757087953\n",
      "Melhor MSE:  0.00021665703447995053\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0002585966580300535\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0013050642715440024\n",
      "Melhor MSE:  0.00035639861226583624\n",
      "Melhor MSE:  9.758163878525933e-05\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.00158986033821489\n",
      "Melhor MSE:  0.0005737596588886659\n",
      "Melhor MSE:  0.00043710275339848556\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0004175729832855502\n",
      "Melhor MSE:  0.0003557587517491353\n",
      "Melhor MSE:  0.0003440093394953378\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0001892512172305636\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0017562182059689692\n",
      "Melhor MSE:  0.0003815028947290896\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0007478979226928736\n",
      "Melhor MSE:  0.0005934416244023524\n",
      "Melhor MSE:  0.000347603136167681\n",
      "Melhor MSE:  0.00021707420928717552\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  2.8888967039758473\n",
      "Melhor MSE:  0.006031195117779951\n",
      "Melhor MSE:  0.0013302551390606883\n",
      "Melhor MSE:  0.0012694638883031476\n",
      "Melhor MSE:  0.0007930450352085902\n",
      "Melhor MSE:  0.000792287982044775\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.006116120133486827\n",
      "Melhor MSE:  0.0035331118045783356\n",
      "Melhor MSE:  0.0014239029790811728\n",
      "Melhor MSE:  0.001226152131611907\n",
      "Execução:  10\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.002336954515698198\n",
      "Melhor MSE:  0.0003380568710573938\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.00028775713494075055\n",
      "Melhor MSE:  0.00023298328453624342\n",
      "Melhor MSE:  0.00019761419311400516\n",
      "Melhor MSE:  0.00016724380315234064\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.00011904331951465778\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.002806954749779858\n",
      "Melhor MSE:  0.0005530218858073343\n",
      "Melhor MSE:  0.0005294968843561056\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.00330979591886617\n",
      "Melhor MSE:  0.001375546936831792\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.000811598251612299\n",
      "Melhor MSE:  0.00039771858815698723\n",
      "Melhor MSE:  0.000204028263783664\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0009942493533421648\n",
      "Melhor MSE:  0.0002509742359283581\n",
      "Melhor MSE:  0.00020868743360273758\n",
      "Melhor MSE:  9.757273438732228e-05\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.001536896320951371\n",
      "Melhor MSE:  0.0006931881072176385\n",
      "Melhor MSE:  0.00045099764306285423\n",
      "Melhor MSE:  0.00012180855795272429\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.00034906424038581363\n",
      "Melhor MSE:  0.00029552087536184466\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.002113391416115945\n",
      "Melhor MSE:  0.0010110123772028073\n",
      "Melhor MSE:  0.0009348784201048842\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0015831217321900127\n",
      "Melhor MSE:  0.000587436015522494\n",
      "Melhor MSE:  0.0004883657197623704\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.001022802771800218\n",
      "Melhor MSE:  0.00045423459797902223\n",
      "Melhor MSE:  0.00038341995702793723\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0004710211065926586\n",
      "Melhor MSE:  0.0002516573852043511\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.00041360362767929257\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0008847686622683065\n",
      "Melhor MSE:  0.0002511916579447427\n",
      "Melhor MSE:  0.00018638327070657996\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0016168170952760683\n",
      "Melhor MSE:  0.0011852359570707824\n",
      "Melhor MSE:  0.00035285978797373917\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0008429405589233682\n",
      "Melhor MSE:  0.0003141322036188578\n",
      "Melhor MSE:  0.00017849228174972404\n",
      "Melhor MSE:  0.00012844768327696166\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0001884339387506034\n",
      "Melhor MSE:  0.00010549843881677643\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0003758069476136538\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0011246495611254026\n",
      "Melhor MSE:  0.0006875979661490253\n",
      "Melhor MSE:  0.00019535075038560533\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0015821598841560779\n",
      "Melhor MSE:  0.0014418625839756624\n",
      "Melhor MSE:  0.0012596001084583316\n",
      "Melhor MSE:  0.0010158796743677475\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0033913962646645213\n",
      "Melhor MSE:  0.0015379651125453854\n",
      "Melhor MSE:  0.0010657714975014227\n",
      "Execução:  11\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.000789420513146423\n",
      "Melhor MSE:  0.000401401147455452\n",
      "Melhor MSE:  0.00033176969657832534\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0006931847513120476\n",
      "Melhor MSE:  0.00015391980169406246\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.000786039253051062\n",
      "Melhor MSE:  0.0004677136246430153\n",
      "Melhor MSE:  0.0004113391166364002\n",
      "Melhor MSE:  0.0004003751112974024\n",
      "Melhor MSE:  0.00023528070891654204\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.000359220246597617\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  2.8743354748151786\n",
      "Melhor MSE:  0.0025174825001647696\n",
      "Melhor MSE:  0.0005891534270211998\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0006749348866434556\n",
      "Melhor MSE:  0.00013619941437647805\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0005596610412030195\n",
      "Melhor MSE:  0.0002204903023494717\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0006058093871745415\n",
      "Melhor MSE:  0.0005470544388990977\n",
      "Melhor MSE:  0.0004456311053959063\n",
      "Melhor MSE:  0.00027149918506446367\n",
      "Melhor MSE:  0.00025586726977154745\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0004958939538399825\n",
      "Melhor MSE:  0.00037431885746750754\n",
      "Melhor MSE:  0.0002950372322569898\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0009035573531928393\n",
      "Melhor MSE:  0.0008200338198084449\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0010360236881292357\n",
      "Melhor MSE:  0.0008208948359052044\n",
      "Melhor MSE:  0.00048330290611797163\n",
      "Melhor MSE:  0.0004159507555977556\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.004352695700486373\n",
      "Melhor MSE:  0.0004918704491119584\n",
      "Melhor MSE:  0.00045521600722659637\n",
      "Melhor MSE:  0.00018320270055672357\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  2.857053854845601\n",
      "Melhor MSE:  0.0009347251950178032\n",
      "Melhor MSE:  0.0007911526132108014\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0007156716834835949\n",
      "Melhor MSE:  0.0005811618506581487\n",
      "Melhor MSE:  0.00019318473877287255\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0003877693384466744\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0004649325844418973\n",
      "Melhor MSE:  0.00034761536866861876\n",
      "Melhor MSE:  0.0002356105574227438\n",
      "Melhor MSE:  0.00022521606112796796\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.00048683230161229615\n",
      "Melhor MSE:  0.0002595425805240779\n",
      "Melhor MSE:  9.515181028781574e-05\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0014375691125314144\n",
      "Melhor MSE:  0.00011905864716520314\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0013832081664380096\n",
      "Melhor MSE:  0.00033399090140429137\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0006748110588643444\n",
      "Melhor MSE:  0.00027449418484813167\n",
      "Melhor MSE:  0.000274237888914503\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.004423735942634019\n",
      "Melhor MSE:  0.0034099669590541893\n",
      "Melhor MSE:  0.0018955294605311796\n",
      "Melhor MSE:  0.001157342813104343\n",
      "Melhor MSE:  0.00046833734513513346\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0008067089161632878\n",
      "Execução:  12\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  3.0756136392397946\n",
      "Melhor MSE:  0.00023652640480380802\n",
      "Melhor MSE:  0.00015878416520672049\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0001250459606873351\n",
      "Melhor MSE:  0.00012216840438027693\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.00040996447210695457\n",
      "Melhor MSE:  0.00012473451436175454\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.000678283166824022\n",
      "Melhor MSE:  0.0005272883043654378\n",
      "Melhor MSE:  0.00027792577914869694\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0005385668278502834\n",
      "Melhor MSE:  0.000465368039647042\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0016531765768051996\n",
      "Melhor MSE:  0.0009746424024041905\n",
      "Melhor MSE:  0.0006791975591709661\n",
      "Melhor MSE:  0.000596878612418005\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  2.789430794707824\n",
      "Melhor MSE:  0.001221396819067996\n",
      "Melhor MSE:  0.0006104433341472191\n",
      "Melhor MSE:  0.00046695872283118473\n",
      "Melhor MSE:  0.00035012570493059\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  2.7888705634387634\n",
      "Melhor MSE:  0.0004632425424343459\n",
      "Melhor MSE:  8.560324653768985e-05\n",
      "Melhor MSE:  4.325206733131909e-05\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0009286612171003734\n",
      "Melhor MSE:  0.0008882424559834217\n",
      "Melhor MSE:  0.0007084827876529363\n",
      "Melhor MSE:  0.0005604919671642913\n",
      "Melhor MSE:  0.00048710240651833863\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0020676532173677896\n",
      "Melhor MSE:  0.0013839833486461739\n",
      "Melhor MSE:  0.0012892189186271066\n",
      "Melhor MSE:  0.0011894392581840967\n",
      "Melhor MSE:  0.0009631572200435981\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.00122081952396183\n",
      "Melhor MSE:  0.0006619383992211799\n",
      "Melhor MSE:  0.00024274245287768083\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0004789090633579654\n",
      "Melhor MSE:  0.00044408270727689655\n",
      "Melhor MSE:  0.0003164193866909841\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0006314561522953207\n",
      "Melhor MSE:  0.0004653886849747507\n",
      "Melhor MSE:  0.0002721311994051711\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0007867861136658461\n",
      "Melhor MSE:  0.0004855215271826704\n",
      "Melhor MSE:  0.00021775855585984564\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0014442185777149303\n",
      "Melhor MSE:  0.00039954110144158457\n",
      "Melhor MSE:  0.00026260926471247115\n",
      "Melhor MSE:  0.0001377589314859115\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0004165469583657361\n",
      "Melhor MSE:  0.00016750077987072836\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.000723855229451797\n",
      "Melhor MSE:  0.00046856745295519074\n",
      "Melhor MSE:  0.00033164431282538937\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  3.0608835221393718\n",
      "Melhor MSE:  2.8306594713834223\n",
      "Melhor MSE:  0.0003268824728603012\n",
      "Melhor MSE:  0.00029112697464701956\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0004554207344965486\n",
      "Melhor MSE:  3.627594116347034e-05\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.00048192793042775486\n",
      "Melhor MSE:  0.000169610194744885\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0007149288686266034\n",
      "Melhor MSE:  0.0004394329164812966\n",
      "Melhor MSE:  0.00038974032756737217\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  2.9013440195960376\n",
      "Melhor MSE:  0.0026419353564451986\n",
      "Melhor MSE:  0.0017054286064610037\n",
      "Melhor MSE:  0.0009029466475725817\n",
      "Melhor MSE:  0.0006462187419816586\n",
      "Execução:  13\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0001977667219488107\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.000715396518423144\n",
      "Melhor MSE:  0.0005264538520103246\n",
      "Melhor MSE:  0.0003580776563226791\n",
      "Melhor MSE:  0.00011965416078421528\n",
      "Melhor MSE:  6.992023997323015e-05\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0004657178631855505\n",
      "Melhor MSE:  0.00043765298364600603\n",
      "Melhor MSE:  0.00042182279886090893\n",
      "Melhor MSE:  0.00038913703644580244\n",
      "Melhor MSE:  0.0001675017232352446\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0016865507130914346\n",
      "Melhor MSE:  0.0009927095135180107\n",
      "Melhor MSE:  0.0007825960799248437\n",
      "Melhor MSE:  0.0006582817634882948\n",
      "Melhor MSE:  0.00024678357264876693\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0005269248836867261\n",
      "Melhor MSE:  0.0004469221801664354\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0004390165982681003\n",
      "Melhor MSE:  0.0002349038146426091\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0035864311995686283\n",
      "Melhor MSE:  0.00032016381660033053\n",
      "Melhor MSE:  0.00016522010314414375\n",
      "Melhor MSE:  3.165626052552308e-05\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0007017364926820626\n",
      "Melhor MSE:  0.00019995759506158192\n",
      "Melhor MSE:  0.00018991928331618614\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0003310566390583352\n",
      "Melhor MSE:  0.00027579965551532797\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0104272071193472\n",
      "Melhor MSE:  0.0015470817124691699\n",
      "Melhor MSE:  0.00132902404602677\n",
      "Melhor MSE:  0.0009863708300772561\n",
      "Melhor MSE:  0.0009114268456253939\n",
      "Melhor MSE:  0.0006465537081748489\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0003517578218171898\n",
      "Melhor MSE:  0.00023983371641556715\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.002221431030438759\n",
      "Melhor MSE:  0.0002469000202355431\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.00042198477367168426\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  3.0700466835420994\n",
      "Melhor MSE:  2.8215975729199325\n",
      "Melhor MSE:  0.0011823906552392873\n",
      "Melhor MSE:  0.0010692102910815743\n",
      "Melhor MSE:  0.00030464831702715624\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0002125817278613504\n",
      "Melhor MSE:  0.00013777083820640053\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.001641970211421421\n",
      "Melhor MSE:  0.0002150427527998436\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0005488226101012372\n",
      "Melhor MSE:  0.00046210152901404543\n",
      "Melhor MSE:  0.0002929595956833568\n",
      "Melhor MSE:  9.299102156977332e-05\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0002976199432107765\n",
      "Melhor MSE:  0.00012548399752999718\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0006452748728772766\n",
      "Melhor MSE:  0.000337321925039766\n",
      "Melhor MSE:  0.00030446745515074527\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0005171274654824877\n",
      "Melhor MSE:  0.00034177200788110593\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0026271203230488547\n",
      "Melhor MSE:  0.00037116790444440315\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0023659522371997474\n",
      "Melhor MSE:  0.001791829033940658\n",
      "Melhor MSE:  0.001439245693697019\n",
      "Melhor MSE:  0.0006702606718643951\n",
      "Execução:  14\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.00013483857471163164\n",
      "Melhor MSE:  7.710957427663614e-05\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  2.8228415099750217\n",
      "Melhor MSE:  0.00048336061240640375\n",
      "Melhor MSE:  0.00015444515878959198\n",
      "Melhor MSE:  7.788342418270216e-05\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0012814042944923336\n",
      "Melhor MSE:  0.0005123392074251345\n",
      "Melhor MSE:  0.00011323171804107786\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0005045123791578447\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0029237910075190204\n",
      "Melhor MSE:  0.0012158853649641723\n",
      "Melhor MSE:  0.0010241147963833551\n",
      "Melhor MSE:  0.0008437050676738108\n",
      "Melhor MSE:  0.0008353081919356068\n",
      "Melhor MSE:  0.0008121449548040535\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  2.8044221262927267\n",
      "Melhor MSE:  0.0027090946002559938\n",
      "Melhor MSE:  0.0016949116967834225\n",
      "Melhor MSE:  0.001249659395755123\n",
      "Melhor MSE:  0.0002468393232835258\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0002687590212990085\n",
      "Melhor MSE:  0.00018181052961358058\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  2.7888705634387634\n",
      "Melhor MSE:  0.0004493740379428286\n",
      "Melhor MSE:  0.0003974554601109947\n",
      "Melhor MSE:  0.0003213128619246319\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.00036750917040640255\n",
      "Melhor MSE:  0.00035019612343204176\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0012831136740321396\n",
      "Melhor MSE:  0.0011556188434128584\n",
      "Melhor MSE:  0.000995141805930761\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0005959415591790242\n",
      "Melhor MSE:  0.0001879243773559193\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0003886758035623268\n",
      "Melhor MSE:  0.0003182796796904137\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0006608047671807434\n",
      "Melhor MSE:  0.00045430649384302113\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0010613630959370095\n",
      "Melhor MSE:  0.00016917822010331724\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.00024163959167524085\n",
      "Melhor MSE:  0.00017795261293404295\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0005258956273224627\n",
      "Melhor MSE:  0.00020415304364095632\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0006588560094467242\n",
      "Melhor MSE:  0.0001599527804780218\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0004744092258623727\n",
      "Melhor MSE:  0.0002439020314296114\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  3.065713399876639\n",
      "Melhor MSE:  0.00036919076036001056\n",
      "Melhor MSE:  0.0001663549841788253\n",
      "Melhor MSE:  5.028601412659833e-05\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.00038474669761541893\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0007377206438628707\n",
      "Melhor MSE:  0.0007315526265308346\n",
      "Melhor MSE:  0.00017493988780430063\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0014477467370741335\n",
      "Melhor MSE:  0.0013944292923233272\n",
      "Melhor MSE:  0.00030883247015534916\n",
      "Execução:  15\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0003380524908504186\n",
      "Melhor MSE:  0.00011310984828483681\n",
      "Melhor MSE:  7.727693984579067e-05\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  2.8228415099750217\n",
      "Melhor MSE:  0.0004295936191894726\n",
      "Melhor MSE:  0.0003232710012654981\n",
      "Melhor MSE:  0.00023769882828763181\n",
      "Melhor MSE:  2.5288157575981383e-05\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0005964654661781493\n",
      "Melhor MSE:  0.000441263695282144\n",
      "Melhor MSE:  0.00032234545719204554\n",
      "Melhor MSE:  0.00024605748010298573\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0009946404504390873\n",
      "Melhor MSE:  0.0009311679651340948\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0011400890493387572\n",
      "Melhor MSE:  0.0010234627551437504\n",
      "Melhor MSE:  0.0007575429813911797\n",
      "Melhor MSE:  0.0007099184354597218\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.004785402183276884\n",
      "Melhor MSE:  0.002911669820291119\n",
      "Melhor MSE:  0.0026116421460595364\n",
      "Melhor MSE:  0.0008932797236236046\n",
      "Melhor MSE:  0.0006580391108100874\n",
      "Melhor MSE:  0.00013196236032783173\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0010359401155183511\n",
      "Melhor MSE:  0.0008488267625190538\n",
      "Melhor MSE:  0.00019061528316225538\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0026592227164829326\n",
      "Melhor MSE:  0.00038830009712353703\n",
      "Melhor MSE:  0.0001934638006902285\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.000801747900969018\n",
      "Melhor MSE:  0.0005890946987717159\n",
      "Melhor MSE:  0.00043407829576944633\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.00221150916618171\n",
      "Melhor MSE:  0.0019366708139868483\n",
      "Melhor MSE:  0.0004791838017274325\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0010538034356823297\n",
      "Melhor MSE:  0.0004648693499251719\n",
      "Melhor MSE:  0.0002695515809419025\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.00021873671664876098\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.00038675946607632383\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0009873596772460972\n",
      "Melhor MSE:  0.00018910798452662428\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0010193370698110033\n",
      "Melhor MSE:  0.00025683032837727307\n",
      "Melhor MSE:  0.00021090253038769392\n",
      "Melhor MSE:  7.638332760022383e-05\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.00036362877118946337\n",
      "Melhor MSE:  0.0002440602504580169\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0006715405816129522\n",
      "Melhor MSE:  0.0001840553526700953\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0006330520976020418\n",
      "Melhor MSE:  0.0002827615209790492\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0007802776567862003\n",
      "Melhor MSE:  0.0001209417086582212\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0003735913387270231\n",
      "Melhor MSE:  0.0003617682111968727\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0017966867352514787\n",
      "Melhor MSE:  0.000783597914718264\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.01229837933762202\n",
      "Melhor MSE:  0.010607326626351351\n",
      "Melhor MSE:  0.004410445361797459\n",
      "Melhor MSE:  0.0040392486298441894\n",
      "Melhor MSE:  0.0014863071777565732\n",
      "Melhor MSE:  0.0010139279170539675\n",
      "Execução:  16\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0030880549625591763\n",
      "Melhor MSE:  0.0009076397371104333\n",
      "Melhor MSE:  0.000531266698036254\n",
      "Melhor MSE:  0.00017899840751328872\n",
      "Melhor MSE:  0.00012264348946214678\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0002352491633903626\n",
      "Melhor MSE:  0.0001662981679074637\n",
      "Melhor MSE:  0.00010257097517478091\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0003036148466351563\n",
      "Melhor MSE:  0.0002905391290841107\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0020706019206678116\n",
      "Melhor MSE:  0.0020658449397152447\n",
      "Melhor MSE:  0.0013511260626350673\n",
      "Melhor MSE:  0.0007422296992328175\n",
      "Melhor MSE:  0.0005102552716261446\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0018211825912551223\n",
      "Melhor MSE:  0.0009482564143033495\n",
      "Melhor MSE:  0.0005935521969327394\n",
      "Melhor MSE:  0.0004976131406096073\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0004528076802059393\n",
      "Melhor MSE:  0.00014246077609984115\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.000303344421876046\n",
      "Melhor MSE:  0.00018978170123961843\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.004931028904388876\n",
      "Melhor MSE:  0.000950079120124957\n",
      "Melhor MSE:  0.00018179180696942072\n",
      "Melhor MSE:  4.250770932292181e-05\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0004923552406811977\n",
      "Melhor MSE:  0.00042056524825308575\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0009775688643976377\n",
      "Melhor MSE:  0.0007651873922114604\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0022747484539504125\n",
      "Melhor MSE:  0.0020105226544676015\n",
      "Melhor MSE:  0.0016928819829748827\n",
      "Melhor MSE:  0.0013570695269031294\n",
      "Melhor MSE:  0.0003278863336611312\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.00012626009640020577\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0010751866702748377\n",
      "Melhor MSE:  0.0007633074397469945\n",
      "Melhor MSE:  0.00023694486161240022\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0006607858598532686\n",
      "Melhor MSE:  0.0006388057680150812\n",
      "Melhor MSE:  0.0002474371965073762\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0002643008460475208\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.00042402846495682224\n",
      "Melhor MSE:  0.00011399020824695986\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.00010271194436219329\n",
      "Melhor MSE:  6.035733812343348e-05\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0005114102198114229\n",
      "Melhor MSE:  0.0004488010278371732\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0011628050651072532\n",
      "Melhor MSE:  9.861570643085846e-05\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0010970733657590305\n",
      "Melhor MSE:  0.0006338746516728599\n",
      "Melhor MSE:  0.0002811845566363575\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0008558424134971259\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.005974397218899586\n",
      "Melhor MSE:  0.002405425690154093\n",
      "Melhor MSE:  0.0011620662928839588\n",
      "Melhor MSE:  0.0008653043469085454\n",
      "Melhor MSE:  0.0007717064750671708\n",
      "Execução:  17\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  3.0756136392397946\n",
      "Melhor MSE:  0.0008488226825583323\n",
      "Melhor MSE:  0.0002449682966582537\n",
      "Melhor MSE:  8.952262065556603e-05\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0007689583376497383\n",
      "Melhor MSE:  0.0002713462193958114\n",
      "Melhor MSE:  8.018626547571734e-05\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.000510788179427085\n",
      "Melhor MSE:  0.000492660265009806\n",
      "Melhor MSE:  0.00043753883422116194\n",
      "Melhor MSE:  0.00011980431814067917\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.000880198413599784\n",
      "Melhor MSE:  0.0004394730331387788\n",
      "Melhor MSE:  0.00040319639761342545\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0008582079255984494\n",
      "Melhor MSE:  0.0008455504660534535\n",
      "Melhor MSE:  0.0007526223078279923\n",
      "Melhor MSE:  0.00048302552655621924\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0017741802690749097\n",
      "Melhor MSE:  0.0006542577836440856\n",
      "Melhor MSE:  5.6091238904330864e-05\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0005817195921210548\n",
      "Melhor MSE:  0.00017876994675792763\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0005418948499423683\n",
      "Melhor MSE:  0.0005379179723169004\n",
      "Melhor MSE:  0.000479132660076686\n",
      "Melhor MSE:  0.0002544945451693973\n",
      "Melhor MSE:  0.00011293343694348856\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.000728107617578072\n",
      "Melhor MSE:  0.00023235806349407127\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  3.029144379554411\n",
      "Melhor MSE:  0.001008762574961709\n",
      "Melhor MSE:  0.00041462419626107596\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0014114549376026075\n",
      "Melhor MSE:  0.0011167609705424054\n",
      "Melhor MSE:  0.0005917355804389946\n",
      "Melhor MSE:  0.00024960639832815955\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0006702618055862699\n",
      "Melhor MSE:  0.0005880383635443543\n",
      "Melhor MSE:  0.00040172553350205847\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0031400697533838107\n",
      "Melhor MSE:  0.0012029703484836252\n",
      "Melhor MSE:  0.0004347637966647532\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0010353927938953147\n",
      "Melhor MSE:  0.0008663973581778728\n",
      "Melhor MSE:  0.0008483020455579088\n",
      "Melhor MSE:  0.00033220296398241026\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  2.8370673539520688\n",
      "Melhor MSE:  0.00029319459969063\n",
      "Melhor MSE:  0.00016503980296309745\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0011785842157069736\n",
      "Melhor MSE:  0.00022350547823550294\n",
      "Melhor MSE:  8.702811150799077e-05\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.00031827085434395523\n",
      "Melhor MSE:  0.00016865482509013894\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0012468772400627964\n",
      "Melhor MSE:  0.0003110570490020734\n",
      "Melhor MSE:  0.00020483945584224227\n",
      "Melhor MSE:  0.00017484354631655197\n",
      "Melhor MSE:  9.938398883851878e-05\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0003551523397584182\n",
      "Melhor MSE:  0.00019865479746849276\n",
      "Melhor MSE:  6.816278639170072e-05\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0009898449030792229\n",
      "Melhor MSE:  0.0006917118274976107\n",
      "Melhor MSE:  0.0002752476184383829\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  2.8888967039758473\n",
      "Melhor MSE:  0.0018222742171912854\n",
      "Melhor MSE:  0.0010671671288847097\n",
      "Melhor MSE:  0.000967719363251939\n",
      "Melhor MSE:  0.00032895888419391065\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.004228935073813283\n",
      "Melhor MSE:  0.0022683567765103296\n",
      "Melhor MSE:  0.0009012803797097485\n",
      "Execução:  18\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0016617794851960846\n",
      "Melhor MSE:  0.001137881734062674\n",
      "Melhor MSE:  0.000846718565001747\n",
      "Melhor MSE:  0.00047500587452256826\n",
      "Melhor MSE:  0.00032024386791679307\n",
      "Melhor MSE:  0.0002412210343032353\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0002279274892495132\n",
      "Melhor MSE:  0.00011014871013109843\n",
      "Melhor MSE:  7.470110586396006e-05\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0004201525788887373\n",
      "Melhor MSE:  0.00026786819920604667\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0021945283894486663\n",
      "Melhor MSE:  0.0011924147590735752\n",
      "Melhor MSE:  0.0008694549904313604\n",
      "Melhor MSE:  0.0005593944044476281\n",
      "Melhor MSE:  0.00044507770893233964\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0013771815522299051\n",
      "Melhor MSE:  0.0011886298101912854\n",
      "Melhor MSE:  0.0002849000951812063\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0012409501337165448\n",
      "Melhor MSE:  0.0007949942693674124\n",
      "Melhor MSE:  0.0007776799778163975\n",
      "Melhor MSE:  0.00015553501327738645\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0007888814004612422\n",
      "Melhor MSE:  0.00043408149672713843\n",
      "Melhor MSE:  0.00033489827531748537\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  2.7888705634387634\n",
      "Melhor MSE:  0.00013083710603345168\n",
      "Melhor MSE:  3.793145587513628e-05\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0005288923173202355\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0032169596502261595\n",
      "Melhor MSE:  0.002872567976620619\n",
      "Melhor MSE:  0.0022618865890089005\n",
      "Melhor MSE:  0.0009826072746201172\n",
      "Melhor MSE:  0.00046000497245701365\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.00021208852802523793\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.001691827842630078\n",
      "Melhor MSE:  0.0009699165338111713\n",
      "Melhor MSE:  0.0007362616077266409\n",
      "Melhor MSE:  0.0005289448578002137\n",
      "Melhor MSE:  0.00040721209780467924\n",
      "Melhor MSE:  0.00032371168429064256\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0007336480274636695\n",
      "Melhor MSE:  0.0003106111540313892\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0002953804965289969\n",
      "Melhor MSE:  0.00025733455187659354\n",
      "Melhor MSE:  0.0001959895320637025\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.00011839867261875095\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.002743949415494686\n",
      "Melhor MSE:  0.0007324295703560829\n",
      "Melhor MSE:  0.0004612783006351319\n",
      "Melhor MSE:  0.00022958231974835744\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.00023726503997052888\n",
      "Melhor MSE:  0.00016268599597104411\n",
      "Melhor MSE:  0.00014650047660912671\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.00048637370770857795\n",
      "Melhor MSE:  0.0002447140392777658\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.00045227117656792176\n",
      "Melhor MSE:  0.00028456317774029264\n",
      "Melhor MSE:  0.0001185411087759914\n",
      "Melhor MSE:  5.1850534552396054e-05\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.002708650835111713\n",
      "Melhor MSE:  0.001720951058685142\n",
      "Melhor MSE:  0.0005982408134146872\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0032876194760921643\n",
      "Melhor MSE:  0.001061042260450615\n",
      "Melhor MSE:  0.00043726678629302506\n",
      "Melhor MSE:  0.0003411702110072559\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  2.9013440195960376\n",
      "Melhor MSE:  0.006321578953231833\n",
      "Melhor MSE:  0.0037496847554424743\n",
      "Melhor MSE:  0.0032812847651896605\n",
      "Melhor MSE:  0.0013381006403280094\n",
      "Melhor MSE:  0.0007834344181362319\n",
      "Execução:  19\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.004392068670175082\n",
      "Melhor MSE:  0.0001910125450885771\n",
      "Melhor MSE:  6.154177337300287e-05\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0006842015821525963\n",
      "Melhor MSE:  0.00012433550073032973\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0006177935249822075\n",
      "Melhor MSE:  0.0005622469843074348\n",
      "Melhor MSE:  0.0001303057577303426\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0012025032348738094\n",
      "Melhor MSE:  0.0011263562871746278\n",
      "Melhor MSE:  0.0009224787807646261\n",
      "Melhor MSE:  0.0006952060175791355\n",
      "Melhor MSE:  0.0006354156436220917\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0003186816611517257\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0009786638351456296\n",
      "Melhor MSE:  0.00048169677597529204\n",
      "Melhor MSE:  0.0003350273684371615\n",
      "Melhor MSE:  0.0002028623131024156\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0029658940046930343\n",
      "Melhor MSE:  0.00030407814972652\n",
      "Melhor MSE:  0.00025029074056362254\n",
      "Melhor MSE:  0.00018850552439926197\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.00021933102286608117\n",
      "Melhor MSE:  0.0001529916236193658\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.00030589840983061414\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.007992739854503028\n",
      "Melhor MSE:  0.0017748101909618804\n",
      "Melhor MSE:  0.0006822573345030861\n",
      "Melhor MSE:  0.00041837621400626674\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0014405490344340413\n",
      "Melhor MSE:  0.0013735865689152296\n",
      "Melhor MSE:  0.0007088748120066803\n",
      "Melhor MSE:  0.0005038901394638841\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0004473796369595498\n",
      "Melhor MSE:  0.0003971367440388588\n",
      "Melhor MSE:  0.00016562409946479974\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.001882451663426449\n",
      "Melhor MSE:  0.0007856277484965148\n",
      "Melhor MSE:  0.0001935554598906731\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0011338884612775958\n",
      "Melhor MSE:  0.0002555902098116854\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0005113187099065654\n",
      "Melhor MSE:  0.0004456533884612515\n",
      "Melhor MSE:  0.0003645585187737469\n",
      "Melhor MSE:  0.0002788081967893316\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0011668718446329663\n",
      "Melhor MSE:  0.00041671877365973545\n",
      "Melhor MSE:  0.000301533756238537\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.00034210215674092937\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0015291531916592754\n",
      "Melhor MSE:  0.0006705770744134563\n",
      "Melhor MSE:  0.00042570003739916633\n",
      "Melhor MSE:  0.00020254649403266152\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0002316486849043403\n",
      "Melhor MSE:  0.00016640127266165705\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0012178595972663568\n",
      "Melhor MSE:  0.0005195352524522036\n",
      "Melhor MSE:  0.00042391540752881286\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  3.002401527735004\n",
      "Melhor MSE:  0.0028447632205878285\n",
      "Melhor MSE:  0.0010790727203827727\n",
      "Melhor MSE:  0.001018046389163844\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0037568712098654056\n",
      "Melhor MSE:  0.002100996704110727\n",
      "Melhor MSE:  0.0017688700084380962\n",
      "Melhor MSE:  0.001400690967926682\n",
      "Execução:  20\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0009000588339552726\n",
      "Melhor MSE:  0.00028333959842717264\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0009249067230555842\n",
      "Melhor MSE:  0.00024297325464583844\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0002011346565586044\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.001350277641564218\n",
      "Melhor MSE:  0.0006104759172475799\n",
      "Melhor MSE:  0.0004828271011810902\n",
      "Melhor MSE:  0.0004532164206749954\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0009863686973382985\n",
      "Melhor MSE:  0.00039889517135581443\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0006140044492217427\n",
      "Melhor MSE:  9.3660692243563e-05\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.00025538712872588833\n",
      "Melhor MSE:  0.0001800024874890192\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.00025627056861264754\n",
      "Melhor MSE:  5.704864748118206e-05\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  2.833404349806333\n",
      "Melhor MSE:  0.0007401325387471698\n",
      "Melhor MSE:  0.0005128039055554613\n",
      "Melhor MSE:  0.0003509982828568989\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0025771277267232088\n",
      "Melhor MSE:  0.002219135858848357\n",
      "Melhor MSE:  0.0021230818969068064\n",
      "Melhor MSE:  0.00155412013681357\n",
      "Melhor MSE:  0.0008557886914420726\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.002179160004073609\n",
      "Melhor MSE:  0.0012075146268651854\n",
      "Melhor MSE:  0.0007745058046904161\n",
      "Melhor MSE:  0.0007355070512931376\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0002637114875030677\n",
      "Melhor MSE:  0.0002024214155688705\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.002422451905292425\n",
      "Melhor MSE:  0.0023841192224501304\n",
      "Melhor MSE:  0.0008875486074656743\n",
      "Melhor MSE:  0.0004670175837733221\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0007056818191618371\n",
      "Melhor MSE:  0.000401222136341203\n",
      "Melhor MSE:  0.0002005488102477746\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.00013269570431092396\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0009990777610465686\n",
      "Melhor MSE:  0.000943414609016736\n",
      "Melhor MSE:  0.0006913404091214997\n",
      "Melhor MSE:  0.000549050423701859\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.00010435606380297748\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0005270179289277652\n",
      "Melhor MSE:  0.0004612753213630785\n",
      "Melhor MSE:  0.00017682046210048966\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0009166164883109878\n",
      "Melhor MSE:  0.0008325372119346807\n",
      "Melhor MSE:  0.0008245132767525054\n",
      "Melhor MSE:  0.0006896618020917901\n",
      "Melhor MSE:  0.0002989961246102061\n",
      "Melhor MSE:  0.00021192150099510646\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0006745193248623928\n",
      "Melhor MSE:  0.00035211688807452416\n",
      "Melhor MSE:  0.0001981074135602423\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0024288168681299064\n",
      "Melhor MSE:  0.0016820904747903366\n",
      "Melhor MSE:  0.0004546936141336019\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.004152363562036046\n",
      "Melhor MSE:  0.003137754361944797\n",
      "Melhor MSE:  0.0024133974476691074\n",
      "Melhor MSE:  0.0009975258723014268\n",
      "Melhor MSE:  0.0009077963795931133\n",
      "Melhor MSE:  0.0003685500300192647\n",
      "Execução:  21\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0003815376346633476\n",
      "Melhor MSE:  0.000328371576907355\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0005965217912661645\n",
      "Melhor MSE:  0.0003598539471192987\n",
      "Melhor MSE:  0.0003371357384471235\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0009081869013702441\n",
      "Melhor MSE:  0.00010943950264432221\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0007901693558509287\n",
      "Melhor MSE:  0.0006843158099584117\n",
      "Melhor MSE:  0.0006505634670094136\n",
      "Melhor MSE:  0.0003783811250364692\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0016475641318067099\n",
      "Melhor MSE:  0.0005568541536795565\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0016482094480267384\n",
      "Melhor MSE:  0.0011998817085275466\n",
      "Melhor MSE:  0.0004595616217477749\n",
      "Melhor MSE:  0.0003094887628563109\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.001121304230562929\n",
      "Melhor MSE:  0.0002844849888591576\n",
      "Melhor MSE:  0.00010307594430671854\n",
      "Melhor MSE:  5.834816759265028e-05\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0009453032565140266\n",
      "Melhor MSE:  0.0003140057258083771\n",
      "Melhor MSE:  0.00024751142718282883\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0005633755728416792\n",
      "Melhor MSE:  0.00041380195143038103\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0015600603907200447\n",
      "Melhor MSE:  0.0008571858751899592\n",
      "Melhor MSE:  0.0003527434685589704\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.003973096610861538\n",
      "Melhor MSE:  0.0039554561092654756\n",
      "Melhor MSE:  0.0016750379405813959\n",
      "Melhor MSE:  0.0008120413360076851\n",
      "Melhor MSE:  0.0003876788090096843\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.00040999663710995397\n",
      "Melhor MSE:  8.014886474805401e-05\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0019210493692241495\n",
      "Melhor MSE:  0.0014379501714033105\n",
      "Melhor MSE:  0.00014390541820576163\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  2.8215975729199325\n",
      "Melhor MSE:  0.0008065874278959873\n",
      "Melhor MSE:  0.0005766801687485505\n",
      "Melhor MSE:  0.00034486878048924785\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  3.054130546169018\n",
      "Melhor MSE:  0.0006271553548518592\n",
      "Melhor MSE:  0.00032799017505548444\n",
      "Melhor MSE:  0.00022792504561394082\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0006030175572862475\n",
      "Melhor MSE:  0.0003562089121690489\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0002718385767602352\n",
      "Melhor MSE:  0.00020108838067465644\n",
      "Melhor MSE:  0.00014327889239655028\n",
      "Melhor MSE:  4.929444605048035e-05\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0008534851770443772\n",
      "Melhor MSE:  0.000382759669718797\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0009349608122801655\n",
      "Melhor MSE:  0.00010039040079734508\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0007794680961183951\n",
      "Melhor MSE:  0.00047904208937267983\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.00155269344628009\n",
      "Melhor MSE:  0.0013898934341678385\n",
      "Melhor MSE:  0.0010210472392267825\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0037838067894026012\n",
      "Melhor MSE:  0.003136575781579353\n",
      "Melhor MSE:  0.002037833183435694\n",
      "Melhor MSE:  0.0007372726531534204\n",
      "Melhor MSE:  0.0006535678720633139\n",
      "Execução:  22\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.00040915567986989966\n",
      "Melhor MSE:  0.0002184754569403613\n",
      "Melhor MSE:  8.126618486420106e-05\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0001115257661961638\n",
      "Melhor MSE:  0.00010374640623429365\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0002679916448175626\n",
      "Melhor MSE:  0.0001069957642339483\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  3.0267253762654662\n",
      "Melhor MSE:  0.0015083722927840904\n",
      "Melhor MSE:  0.0014662416186792125\n",
      "Melhor MSE:  0.001227357771306625\n",
      "Melhor MSE:  0.001080526121032482\n",
      "Melhor MSE:  0.0010727751743819052\n",
      "Melhor MSE:  0.0010307356776934056\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  2.8743354748151786\n",
      "Melhor MSE:  0.004987730020294402\n",
      "Melhor MSE:  0.0038790344370760676\n",
      "Melhor MSE:  0.0005281718843626026\n",
      "Melhor MSE:  0.0005150845921178417\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0007695345643920098\n",
      "Melhor MSE:  0.0001720677830296508\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0030269972220514896\n",
      "Melhor MSE:  0.0002195998028689378\n",
      "Melhor MSE:  0.00021438119274459124\n",
      "Melhor MSE:  0.00014701427253654747\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0009657747152413534\n",
      "Melhor MSE:  0.0006959697224748206\n",
      "Melhor MSE:  0.0004920989352040846\n",
      "Melhor MSE:  0.00043180639580709274\n",
      "Melhor MSE:  0.00030173654236139515\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0005458761534985734\n",
      "Melhor MSE:  0.00047652523202742163\n",
      "Melhor MSE:  0.00040733866613644395\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0007048102555224905\n",
      "Melhor MSE:  0.00041809645135695736\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0016295205894928666\n",
      "Melhor MSE:  0.0010998653002617482\n",
      "Melhor MSE:  0.0010643656536605422\n",
      "Melhor MSE:  0.0005518794681976791\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0004940897458409279\n",
      "Melhor MSE:  0.0003544725782111655\n",
      "Melhor MSE:  0.00014625022175320865\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.00032938258152751914\n",
      "Melhor MSE:  0.00031356244776488954\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0002457650491130776\n",
      "Melhor MSE:  0.00016748213273034084\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.00036136573725338556\n",
      "Melhor MSE:  0.00030436365424721043\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.000944179723241527\n",
      "Melhor MSE:  0.000716999068713307\n",
      "Melhor MSE:  0.00026545528524436957\n",
      "Melhor MSE:  0.00023139025396871126\n",
      "Melhor MSE:  0.0002052746894020521\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0002317791524203963\n",
      "Melhor MSE:  0.00017949287310936102\n",
      "Melhor MSE:  0.0001110270862431778\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.00037849264598876955\n",
      "Melhor MSE:  0.000287779746304159\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.002085808114779332\n",
      "Melhor MSE:  0.0007648094565745316\n",
      "Melhor MSE:  0.00021113873046512408\n",
      "Melhor MSE:  0.00010210274432144697\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0009521602119229955\n",
      "Melhor MSE:  0.000730910113855239\n",
      "Melhor MSE:  0.00037587140283077905\n",
      "Melhor MSE:  0.0003717383225609222\n",
      "Melhor MSE:  0.00015929901452882967\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.004484025814109044\n",
      "Melhor MSE:  0.0004963237997473727\n",
      "Melhor MSE:  0.000229134468704456\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.014103502690870878\n",
      "Melhor MSE:  0.005968420988059355\n",
      "Melhor MSE:  0.0013139737221342588\n",
      "Melhor MSE:  0.0005649009188878124\n",
      "Execução:  23\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0007944065524737836\n",
      "Melhor MSE:  0.0004899018167215282\n",
      "Melhor MSE:  0.00021429072225815217\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0003395523921389944\n",
      "Melhor MSE:  9.67225287517839e-05\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0004940432039296032\n",
      "Melhor MSE:  0.0002492399552000822\n",
      "Melhor MSE:  0.00020179225078783094\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.001733632838698209\n",
      "Melhor MSE:  0.00043268517929636766\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.000773034110357109\n",
      "Melhor MSE:  0.0006951361220768967\n",
      "Melhor MSE:  0.0004936041511732901\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0011586949901354407\n",
      "Melhor MSE:  0.000787660124972458\n",
      "Melhor MSE:  0.0004737412043538652\n",
      "Melhor MSE:  0.0002616574194108693\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  3.103623548907296\n",
      "Melhor MSE:  0.0016814071281682583\n",
      "Melhor MSE:  0.0002589921234869973\n",
      "Melhor MSE:  0.00018296969816920884\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.00011977439199603441\n",
      "Melhor MSE:  7.276947327039181e-05\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.00050408895146605\n",
      "Melhor MSE:  0.00041961950423787745\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0009398564719650781\n",
      "Melhor MSE:  0.0009135622838571403\n",
      "Melhor MSE:  0.0006414382804253559\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.003582597433916852\n",
      "Melhor MSE:  0.0012412305111066117\n",
      "Melhor MSE:  0.0005706491515609619\n",
      "Melhor MSE:  0.0003054528852564498\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.000827841370315518\n",
      "Melhor MSE:  0.00046955104690327203\n",
      "Melhor MSE:  0.00015195484991218676\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  2.857053854845601\n",
      "Melhor MSE:  0.00048185313844472023\n",
      "Melhor MSE:  0.00035751735390588313\n",
      "Melhor MSE:  0.0003121339295207978\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0007803333916111888\n",
      "Melhor MSE:  0.00037017081679260796\n",
      "Melhor MSE:  0.00022497365131027338\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  2.8370673539520688\n",
      "Melhor MSE:  0.00040112811685011763\n",
      "Melhor MSE:  0.00022249533214337218\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0004766926486966795\n",
      "Melhor MSE:  0.0003943040923234341\n",
      "Melhor MSE:  0.0003699551608490099\n",
      "Melhor MSE:  0.00035033314133181743\n",
      "Melhor MSE:  0.00023220121942692416\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.00019795628064553491\n",
      "Melhor MSE:  0.00018614872918977973\n",
      "Melhor MSE:  0.00014618548679355207\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.00028687578502437403\n",
      "Melhor MSE:  0.000210614626165314\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0009209166030548458\n",
      "Melhor MSE:  0.0005276741092038197\n",
      "Melhor MSE:  0.0003082165694922642\n",
      "Melhor MSE:  0.00020107973906117278\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0004616566986454829\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0018116235365609878\n",
      "Melhor MSE:  0.0014366118543499666\n",
      "Melhor MSE:  0.0011187154903262574\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.007019348652543265\n",
      "Melhor MSE:  0.006493068783313727\n",
      "Melhor MSE:  0.0031945781210878663\n",
      "Melhor MSE:  0.0014574987229585858\n",
      "Execução:  24\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0005440238416710434\n",
      "Melhor MSE:  0.0004194380544354265\n",
      "Melhor MSE:  0.0001785568771409762\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0001486216872233075\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.00020304556916385922\n",
      "Melhor MSE:  0.00020212047619033133\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.00048616256717972094\n",
      "Melhor MSE:  0.00045841042691555057\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0014599289500412042\n",
      "Melhor MSE:  0.0014328246707730411\n",
      "Melhor MSE:  0.000704277196538201\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  2.8044221262927267\n",
      "Melhor MSE:  0.00028275169151502827\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.008417664679187909\n",
      "Melhor MSE:  0.002771194868646791\n",
      "Melhor MSE:  0.0005241189480700868\n",
      "Melhor MSE:  0.000255905854376689\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0020006921367327485\n",
      "Melhor MSE:  0.0004604472409457642\n",
      "Melhor MSE:  0.00023670810426198817\n",
      "Melhor MSE:  0.00019665798569111606\n",
      "Melhor MSE:  0.00010309768141046845\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0012569134251756943\n",
      "Melhor MSE:  0.0005138581991855693\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.002461087971257749\n",
      "Melhor MSE:  0.002421491166697488\n",
      "Melhor MSE:  0.0006744636961597526\n",
      "Melhor MSE:  0.0004766958591324343\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0003535299484981101\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.00038451433915453684\n",
      "Melhor MSE:  0.00036594615343432023\n",
      "Melhor MSE:  0.00035843263066435955\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.000978370930587135\n",
      "Melhor MSE:  0.00021309403994235394\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.00040116043379070725\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0005391533083792429\n",
      "Melhor MSE:  0.00024068819231144224\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0008818109335755094\n",
      "Melhor MSE:  0.00032260754406409687\n",
      "Melhor MSE:  0.0002817563112480908\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.00025014404127301565\n",
      "Melhor MSE:  0.0001123531085560917\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  3.0608835221393718\n",
      "Melhor MSE:  0.00012122851645267919\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.00019001487000561336\n",
      "Melhor MSE:  0.00017902280544235112\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0013252596259710743\n",
      "Melhor MSE:  0.0005904935787598994\n",
      "Melhor MSE:  0.000431270246548619\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.001265888515011149\n",
      "Melhor MSE:  0.0010362851186312583\n",
      "Melhor MSE:  0.0009520394840281059\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  2.9909530909848465\n",
      "Melhor MSE:  0.0012379951741107525\n",
      "Execução:  25\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0014260338742361214\n",
      "Melhor MSE:  0.00013343563543412223\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.000384447404960712\n",
      "Melhor MSE:  0.00035048932023142314\n",
      "Melhor MSE:  0.0002207232373060944\n",
      "Melhor MSE:  5.515248027944133e-05\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0003256187075464831\n",
      "Melhor MSE:  0.00014505403772370565\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.003940826213117258\n",
      "Melhor MSE:  0.0017153622212435285\n",
      "Melhor MSE:  0.0005997758599023935\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.007587234842742917\n",
      "Melhor MSE:  0.0009830064302330508\n",
      "Melhor MSE:  0.0004892133790932952\n",
      "Melhor MSE:  0.0003496445875213986\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0007294572237002944\n",
      "Melhor MSE:  0.00045869674616567897\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0003066811076181137\n",
      "Melhor MSE:  0.00012415363705851881\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.002847643614460537\n",
      "Melhor MSE:  6.994292120277228e-05\n",
      "Melhor MSE:  3.932621379075212e-05\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0005759736646013939\n",
      "Melhor MSE:  0.0005169103845926397\n",
      "Melhor MSE:  0.00029894452412797186\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0009975381124357572\n",
      "Melhor MSE:  0.0008520455643991215\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0011599030228857045\n",
      "Melhor MSE:  0.0005755435575110157\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.000730442692873531\n",
      "Melhor MSE:  0.00016807847514774092\n",
      "Melhor MSE:  0.00015011880044791599\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0007643406632441563\n",
      "Melhor MSE:  0.0003155900974460594\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0019035299512077674\n",
      "Melhor MSE:  0.0002769143504441939\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.00012091927095933576\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  2.8250337175845615\n",
      "Melhor MSE:  0.0005100103024779874\n",
      "Melhor MSE:  0.00022910199793269294\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  3.074774009780418\n",
      "Melhor MSE:  0.00034935920732931337\n",
      "Melhor MSE:  0.00030455210382712575\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0008576127044928025\n",
      "Melhor MSE:  0.00046765102704397\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  2.8259067885254736\n",
      "Melhor MSE:  6.41257035159075e-05\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0010032581856620722\n",
      "Melhor MSE:  0.0004938070994978441\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0009344552779883723\n",
      "Melhor MSE:  0.0003906331460032505\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  2.9013440195960376\n",
      "Melhor MSE:  0.0019059629852292747\n",
      "Melhor MSE:  0.0011822191999501662\n",
      "Execução:  26\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0007103241200087742\n",
      "Melhor MSE:  0.00025734411234922124\n",
      "Melhor MSE:  6.629669681910076e-05\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.00024579366286526925\n",
      "Melhor MSE:  0.00019313417392752364\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0003580158926251377\n",
      "Melhor MSE:  0.00015591436414122092\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0027063492962225624\n",
      "Melhor MSE:  0.0010889063427684568\n",
      "Melhor MSE:  0.0008786156181462015\n",
      "Melhor MSE:  0.0005540677016967169\n",
      "Melhor MSE:  0.00046136893911044195\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  3.0164666821246002\n",
      "Melhor MSE:  0.003656278330855997\n",
      "Melhor MSE:  0.0009244416303733685\n",
      "Melhor MSE:  0.0006952123160615232\n",
      "Melhor MSE:  0.0004959496932004163\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0012450576423602133\n",
      "Melhor MSE:  0.00023591341145537794\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0008732768721988228\n",
      "Melhor MSE:  0.00028026953266853307\n",
      "Melhor MSE:  0.0001272178772404048\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.00046208162715603347\n",
      "Melhor MSE:  8.182110514096607e-05\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0005669565126727157\n",
      "Melhor MSE:  0.0005238892811605939\n",
      "Melhor MSE:  0.0005124439975003283\n",
      "Melhor MSE:  0.0004692857265771652\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0011880520566211064\n",
      "Melhor MSE:  0.0011342770480842132\n",
      "Melhor MSE:  0.0008850014396318202\n",
      "Melhor MSE:  0.0004005679624932753\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0010688676949098177\n",
      "Melhor MSE:  0.0008764989556368902\n",
      "Melhor MSE:  0.0005369615305971758\n",
      "Melhor MSE:  0.0004912281254841042\n",
      "Melhor MSE:  0.0004478669849173777\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0003185150265802148\n",
      "Melhor MSE:  0.00028343546663708554\n",
      "Melhor MSE:  0.00015240964431550535\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0013212650514816144\n",
      "Melhor MSE:  0.0006580091936194955\n",
      "Melhor MSE:  0.0001817233377968503\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0009525312932988479\n",
      "Melhor MSE:  0.0007862707720737721\n",
      "Melhor MSE:  0.0006360029575429351\n",
      "Melhor MSE:  0.00037512135151426796\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0008233191029115043\n",
      "Melhor MSE:  0.00035956983408424147\n",
      "Melhor MSE:  0.00027343260064109225\n",
      "Melhor MSE:  5.2773453680343996e-05\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0006594484676983925\n",
      "Melhor MSE:  0.00026615676633385616\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0015450220151680305\n",
      "Melhor MSE:  0.001053289865758932\n",
      "Melhor MSE:  0.0007379571016019072\n",
      "Melhor MSE:  0.0001572447585215373\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0009013931416891521\n",
      "Melhor MSE:  0.0004122835657889569\n",
      "Melhor MSE:  0.0003993785095788554\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0009008141624609868\n",
      "Melhor MSE:  0.0005982644167430708\n",
      "Melhor MSE:  0.00044817409333817207\n",
      "Melhor MSE:  0.00025937006996885035\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.00029219288087331915\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.002091091096751817\n",
      "Melhor MSE:  0.0007933784204320167\n",
      "Melhor MSE:  0.0007331641730569053\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0018297803582646246\n",
      "Melhor MSE:  0.0008112435305264237\n",
      "Melhor MSE:  0.000618854555272646\n",
      "Execução:  27\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0006193232128717725\n",
      "Melhor MSE:  0.00039895947365305856\n",
      "Melhor MSE:  0.00033317205623523274\n",
      "Melhor MSE:  0.00020375332561903243\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.00021560961913497274\n",
      "Melhor MSE:  0.00013266938197142796\n",
      "Melhor MSE:  6.47490405341622e-05\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0019626086672697132\n",
      "Melhor MSE:  0.00028966913844939344\n",
      "Melhor MSE:  0.00027556336498369213\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0032722664818794615\n",
      "Melhor MSE:  0.0008737922261540111\n",
      "Melhor MSE:  0.0005202782695828199\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0011644467515183822\n",
      "Melhor MSE:  0.0006678774486975789\n",
      "Melhor MSE:  0.00040871825812686035\n",
      "Melhor MSE:  0.0002720131537274292\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0035950672034471194\n",
      "Melhor MSE:  0.0007520119197053944\n",
      "Melhor MSE:  0.0005159781007904413\n",
      "Melhor MSE:  0.0003674054528052755\n",
      "Melhor MSE:  0.00032001668000724534\n",
      "Melhor MSE:  0.00010164968816584639\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0003942185965133823\n",
      "Melhor MSE:  0.00014756028509992192\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0005254498760162188\n",
      "Melhor MSE:  0.0002097174993550796\n",
      "Melhor MSE:  0.00011822505123632456\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0011784120721744788\n",
      "Melhor MSE:  0.0005756344161885048\n",
      "Melhor MSE:  0.0003706820735853625\n",
      "Melhor MSE:  0.0001829769306219289\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.003547496262252142\n",
      "Melhor MSE:  0.0015591707221827074\n",
      "Melhor MSE:  0.0013303957832027523\n",
      "Melhor MSE:  0.00047585771799225473\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.00084449779030239\n",
      "Melhor MSE:  0.0004939772512145524\n",
      "Melhor MSE:  0.0004549514119058381\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0008234623236687783\n",
      "Melhor MSE:  0.00035267302517877987\n",
      "Melhor MSE:  0.00034613570031672276\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0017588416315385607\n",
      "Melhor MSE:  0.0009519330155743279\n",
      "Melhor MSE:  0.0006820157583419458\n",
      "Melhor MSE:  0.0005547858029944653\n",
      "Melhor MSE:  0.0003586858279968996\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.006056719429539358\n",
      "Melhor MSE:  0.00038393249452048307\n",
      "Melhor MSE:  0.00029761619660649953\n",
      "Melhor MSE:  8.994970898556214e-05\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.000329897994466515\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0005082638806889077\n",
      "Melhor MSE:  0.00033468003692399036\n",
      "Melhor MSE:  0.00026094651632355294\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  2.817045584151492\n",
      "Melhor MSE:  0.0001306919893706464\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0006378220151063814\n",
      "Melhor MSE:  0.00014346537077760814\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.000502362043423058\n",
      "Melhor MSE:  0.00033991924795005496\n",
      "Melhor MSE:  0.0001743029323518552\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.00043492117071864235\n",
      "Melhor MSE:  0.0001699984527140174\n",
      "Melhor MSE:  0.00010637237024776927\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0018364729791939358\n",
      "Melhor MSE:  0.001002332346680834\n",
      "Melhor MSE:  0.0005313719896416891\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0067995014303462616\n",
      "Melhor MSE:  0.0015106752675680892\n",
      "Melhor MSE:  0.0007499140406611499\n",
      "Execução:  28\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.00011947309377208779\n",
      "Melhor MSE:  8.825203456076916e-05\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0004732709887828304\n",
      "Melhor MSE:  0.00015211245864813866\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0006771189651219956\n",
      "Melhor MSE:  0.00043946634801669067\n",
      "Melhor MSE:  0.00038684976131354127\n",
      "Melhor MSE:  0.00015733982443551846\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.002012790969530754\n",
      "Melhor MSE:  0.0006883158674491716\n",
      "Melhor MSE:  0.0002575712660530792\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.001177240621946641\n",
      "Melhor MSE:  0.00039950991864191144\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0007885265086878602\n",
      "Melhor MSE:  0.0005445803033882119\n",
      "Melhor MSE:  0.0003092146373449175\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  3.103623548907296\n",
      "Melhor MSE:  0.00031915033875132493\n",
      "Melhor MSE:  6.269891723331219e-05\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0005312562762745893\n",
      "Melhor MSE:  0.0001369034174807305\n",
      "Melhor MSE:  0.00011467153026668275\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0010004315829694286\n",
      "Melhor MSE:  0.0006938042682259096\n",
      "Melhor MSE:  0.0005932589011018735\n",
      "Melhor MSE:  0.00040603056168878754\n",
      "Melhor MSE:  0.0003676431123986083\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0022882871024571443\n",
      "Melhor MSE:  0.001866044352018272\n",
      "Melhor MSE:  0.0007231800437846127\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0003493663662946811\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0006063915213591533\n",
      "Melhor MSE:  0.00010064650421491784\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.004181346317931467\n",
      "Melhor MSE:  0.0006764255673259188\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.00047390850914881717\n",
      "Melhor MSE:  0.0004142084793400676\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0003200991881913345\n",
      "Melhor MSE:  0.0003094862390291097\n",
      "Melhor MSE:  0.00029516140213804184\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.00033158393236432343\n",
      "Melhor MSE:  0.000202936075819127\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0003986181441829528\n",
      "Melhor MSE:  0.0001877876483293451\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.00038508332204661544\n",
      "Melhor MSE:  0.0002994950640049587\n",
      "Melhor MSE:  0.0001778857755956123\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  2.8259067885254736\n",
      "Melhor MSE:  0.00015248256960642632\n",
      "Melhor MSE:  9.234671897067611e-05\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0006844711761116582\n",
      "Melhor MSE:  0.00028889532081186406\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0009658030340451144\n",
      "Melhor MSE:  0.0007286415419417727\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.011247905164853038\n",
      "Melhor MSE:  0.002538858513051453\n",
      "Melhor MSE:  0.0025197768026508608\n",
      "Melhor MSE:  0.0009172736270023374\n",
      "Execução:  29\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0010170573305316654\n",
      "Melhor MSE:  0.0009256020201440373\n",
      "Melhor MSE:  0.0003642493204339015\n",
      "Melhor MSE:  0.00035516116041901314\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0014184667265074776\n",
      "Melhor MSE:  0.00019129527133795364\n",
      "Melhor MSE:  0.00017918649517351164\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  2.845040496503207\n",
      "Melhor MSE:  0.00048548065457221625\n",
      "Melhor MSE:  0.0003823453868428123\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0009582102760579209\n",
      "Melhor MSE:  0.000455209502309442\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.000740174026473882\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  3.087805128705048\n",
      "Melhor MSE:  0.00424176364850021\n",
      "Melhor MSE:  0.001276903759678748\n",
      "Melhor MSE:  0.001068171229422244\n",
      "Melhor MSE:  0.0008291993036922879\n",
      "Melhor MSE:  0.0005633350945090641\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0015665992245915284\n",
      "Melhor MSE:  0.0007433923141987659\n",
      "Melhor MSE:  0.0006018736950614257\n",
      "Melhor MSE:  0.00045370929848144524\n",
      "Melhor MSE:  0.00041332261928647793\n",
      "Melhor MSE:  0.0003659449808149863\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0005758857806807733\n",
      "Melhor MSE:  0.00017670329867237126\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0005229336496844193\n",
      "Melhor MSE:  0.0004635413312434904\n",
      "Melhor MSE:  0.0003545267876627365\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.000814574096775257\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.001846918253397235\n",
      "Melhor MSE:  0.0003933381252934369\n",
      "Melhor MSE:  0.00031390240989289953\n",
      "Melhor MSE:  0.00014952913612481118\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0002521664562453957\n",
      "Melhor MSE:  0.00023316344594939445\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0005488529844871552\n",
      "Melhor MSE:  0.0004089293379344118\n",
      "Melhor MSE:  0.0002957654022030676\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0005940060867609241\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0012965449413599177\n",
      "Melhor MSE:  0.0008902254826247667\n",
      "Melhor MSE:  0.00018780567505554397\n",
      "Melhor MSE:  0.00010822055572418771\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.00043283282461595627\n",
      "Melhor MSE:  0.0001283039677223836\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0002701536538769885\n",
      "Melhor MSE:  0.00020825873528090445\n",
      "Melhor MSE:  0.00018146192651791364\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.00047197497002060535\n",
      "Melhor MSE:  0.00040477834752539546\n",
      "Melhor MSE:  0.00036780742639335123\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0002355701659533276\n",
      "Melhor MSE:  0.00017797667235644124\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0016634759503200496\n",
      "Melhor MSE:  0.001207122584892122\n",
      "Melhor MSE:  0.0008478024746525362\n",
      "Melhor MSE:  0.0005501625882272067\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.0019182789576257663\n",
      "Melhor MSE:  0.0012322269024097187\n",
      "Melhor MSE:  0.0011862527042436418\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Melhor MSE:  0.002937975072114767\n",
      "Melhor MSE:  0.002898098678251371\n",
      "Melhor MSE:  0.0014482342017869089\n"
     ]
    }
   ],
   "source": [
    "# Criando cenários\n",
    "X_I = cenarios_dinamicos(X, 60, 10)\n",
    "y_I = cenarios_dinamicos(y, 60, 10)\n",
    "\n",
    "\n",
    "mse_treino = np.zeros((30, len(y_I)))\n",
    "mse_teste = np.zeros((30, len(y_I)))\n",
    "\n",
    "## Precisamos fazer 30 execuções e computar a média e o desvio padrão\n",
    "execucoes = np.arange(30)\n",
    "\n",
    "for execucao in execucoes:\n",
    "\n",
    "    print('Execução: ', execucao)\n",
    "    \n",
    "    # Janelamento\n",
    "    for i in np.arange(len(y_I)):\n",
    "    \n",
    "        ## Divisão em treinamento e teste\n",
    "        X_treino, y_treino, X_teste, y_teste, X_validacao, y_validacao = divisao_dados_temporais(X_I[i], y_I[i], perc_treino=.56, perc_val = .24)\n",
    "    \n",
    "        ### Treinar rede neural com backprop\n",
    "        # setando parâmetros para comparação\n",
    "        best_model = 0\n",
    "        best_mse = np.inf\n",
    "\n",
    "        # quantidade de neurônios de 2 até 25\n",
    "        neuronios = np.arange(2, 26)\n",
    "    \n",
    "        # grid search \n",
    "        for j in neuronios:\n",
    "            #print('Neurônios: ', j)\n",
    "        \n",
    "            # treinar NN para f iterações\n",
    "            parameters = nn_model2(X_treino.T, y_treino.T, n_h = j, num_iterations = f)\n",
    "        \n",
    "            # predição na validação\n",
    "            y_pred_val = predict2(parameters, X_validacao.T)\n",
    "            mse_validacao = compute_cost2(y_pred_val, y_validacao.T, parameters)\n",
    "        \n",
    "            if mse_validacao < best_mse:\n",
    "                best_model = parameters \n",
    "                best_mse = mse_validacao\n",
    "                #print('Melhor MSE: ', best_mse)\n",
    "                qtd_neuronios = j\n",
    "                \n",
    "        # retreinar e retestar com a melhor topologia \n",
    "        y_pred_treino = predict2(best_model, X_treino.T)\n",
    "        mse_treino_temp = compute_cost2(y_pred_treino, y_treino.T, best_model)\n",
    "        mse_treino[execucoes,i] = mse_treino_temp\n",
    "    \n",
    "        y_pred_teste = predict2(best_model, X_teste.T)\n",
    "        mse_teste_temp = compute_cost2(y_pred_teste, y_teste.T, best_model)\n",
    "        mse_teste[execucoes,i] = mse_teste_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TE medio:  8.237795264411928e-06\n",
      "TE desvio:  1.6940658945086007e-21\n",
      "GE medio:  1.2738236661669974e-05\n",
      "GE desvio:  1.2738236661669974e-05\n",
      "GF medio:  1.546316247588769\n",
      "GF desvio:  2.220446049250313e-16\n"
     ]
    }
   ],
   "source": [
    "# Precisamos ver como calcular o Training erro e o Generalization error (teste)\n",
    "\n",
    "te = np.apply_along_axis(cmf, 1, mse_treino, T)\n",
    "ge = np.apply_along_axis(cmf, 1, mse_teste, T)\n",
    "\n",
    "# calcular a métrica fator de generalização\n",
    "gf = ge/te\n",
    "\n",
    "# Média e desvio padrão\n",
    "te_medio = np.apply_along_axis(cmf, 1, mse_treino, T).mean()\n",
    "te_std = np.apply_along_axis(cmf, 1, mse_treino, T).std()\n",
    "\n",
    "ge_medio = np.apply_along_axis(cmf, 1, mse_teste, T).mean()\n",
    "ge_std = np.apply_along_axis(cmf, 1, mse_teste, T).mean()\n",
    "\n",
    "gf_medio = gf.mean()\n",
    "gf_std = gf.std()\n",
    "\n",
    "print('TE medio: ', te_medio)\n",
    "print('TE desvio: ', te_std)\n",
    "print('GE medio: ', ge_medio)\n",
    "print('GE desvio: ', ge_std)\n",
    "print('GF medio: ', gf_medio)\n",
    "print('GF desvio: ', gf_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PSO padrão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Criando cenários\n",
    "def cenarios_execucoes(X, y, w, s, f, modelo, qtd_execucoes = 30):\n",
    "    \n",
    "    X_I = cenarios_dinamicos(X, 60, 10)\n",
    "    y_I = cenarios_dinamicos(y, 60, 10)\n",
    "\n",
    "    mse_treino = np.zeros((qtd_execucoes, len(y_I)))\n",
    "    mse_teste = np.zeros((qtd_execucoes, len(y_I)))\n",
    "\n",
    "    execucoes = np.arange(qtd_execucoes)\n",
    "\n",
    "    for execucao in execucoes:\n",
    "\n",
    "        print('Execução: ', execucao)\n",
    "    \n",
    "        # Janelamento\n",
    "        for i in np.arange(len(y_I)):\n",
    "    \n",
    "            ## Divisão em treinamento e teste\n",
    "            X_treino, y_treino, X_teste, y_teste, X_validacao, y_validacao = divisao_dados_temporais(X_I[i], y_I[i], perc_treino=.56, perc_val = .24)\n",
    "    \n",
    "            ### Treinar rede neural com backprop\n",
    "            # setando parâmetros para comparação\n",
    "            best_model = 0\n",
    "            best_mse = np.inf\n",
    "\n",
    "            # quantidade de neurônios de 2 até 25\n",
    "            neuronios = np.arange(2, 26)\n",
    "    \n",
    "            # grid search \n",
    "            for j in neuronios:\n",
    "                #print('Neurônios: ', j)\n",
    "        \n",
    "                # treinar NN para f iterações\n",
    "                parameters = modelo(X_treino.T, y_treino.T, n_h = j, num_iterations = f)\n",
    "        \n",
    "                # predição na validação\n",
    "                y_pred_val = predict2(parameters, X_validacao.T)\n",
    "                mse_validacao = compute_cost2(y_pred_val, y_validacao.T, parameters)\n",
    "        \n",
    "                if mse_validacao < best_mse:\n",
    "                    best_model = parameters \n",
    "                    best_mse = mse_validacao\n",
    "                    #print('Melhor MSE: ', best_mse)\n",
    "                    qtd_neuronios = j\n",
    "                \n",
    "            # retreinar e retestar com a melhor topologia \n",
    "            y_pred_treino = predict2(best_model, X_treino.T)\n",
    "            mse_treino_temp = compute_cost2(y_pred_treino, y_treino.T, best_model)\n",
    "            mse_treino[execucoes,i] = mse_treino_temp\n",
    "        \n",
    "            y_pred_teste = predict2(best_model, X_teste.T)\n",
    "            mse_teste_temp = compute_cost2(y_pred_teste, y_teste.T, best_model)\n",
    "            mse_teste[execucoes,i] = mse_teste_temp\n",
    "\n",
    "    return mse_treino, mse_teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "## Criando avaliação dos resultados\n",
    "def avaliacao_resultados(mse_treino, mse_teste, T):\n",
    "    \n",
    "    te = np.apply_along_axis(cmf, 1, mse_treino, T)\n",
    "    ge = np.apply_along_axis(cmf, 1, mse_teste, T)\n",
    "\n",
    "    # calcular a métrica fator de generalização\n",
    "    gf = ge/te\n",
    "\n",
    "    # Média e desvio padrão\n",
    "    te_medio = np.apply_along_axis(cmf, 1, mse_treino, T).mean()\n",
    "    te_std = np.apply_along_axis(cmf, 1, mse_treino, T).std()\n",
    "\n",
    "    ge_medio = np.apply_along_axis(cmf, 1, mse_teste, T).mean()\n",
    "    ge_std = np.apply_along_axis(cmf, 1, mse_teste, T).mean()\n",
    "\n",
    "    gf_medio = gf.mean()\n",
    "    gf_std = gf.std()\n",
    "\n",
    "    print('TE medio: ', te_medio)\n",
    "    print('TE desvio: ', te_std)\n",
    "    print('GE medio: ', ge_medio)\n",
    "    print('GE desvio: ', ge_std)\n",
    "    print('GF medio: ', gf_medio)\n",
    "    print('GF desvio: ', gf_std)\n",
    "    \n",
    "    resultados = {'TE medio': te_medio,\n",
    "    'TE desvio': te_std,\n",
    "    'GE medio': ge_medio,\n",
    "    'GE desvio':ge_std,\n",
    "    'GF medio':gf_medio,\n",
    "    'GF desvio':gf_std}\n",
    "    \n",
    "    return resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cenário II - Sunspot\n",
    "\n",
    "1. Testando Cenário I\n",
    "\n",
    "* w = 60\n",
    "* s = 20\n",
    "* f = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantidade total de iterações:  1495.0\n",
      "Execução:  0\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Execução:  1\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Execução:  2\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Execução:  3\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Execução:  4\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Execução:  5\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n",
      "Particao de Treinamento: 0 33\n",
      "Particao de Validacao: 33 47\n",
      "Particao de Teste: 47 60\n"
     ]
    }
   ],
   "source": [
    "w = 60 # tamanho da janela\n",
    "s = 20 # tamanho do passo\n",
    "f = 100 # quantidade de iterações para a janela\n",
    "T = f/s*(len(y))+f\n",
    "print('Quantidade total de iterações: ', T)\n",
    "\n",
    "mse_treino_2, mse_teste_2 = cenarios_execucoes(X, y, w, s, f, modelo = nn_model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-40-d996d042c38a>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-40-d996d042c38a>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    avaliacao_resultados(mse_treino_2, mse_teste_2,\u001b[0m\n\u001b[0m                                                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "resultados_2 = avaliacao_resultados(mse_treino_2, mse_teste_2, T) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Airline Time Series\n",
    "\n",
    "Série mensal\n",
    "Inputs: 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Airline Passenger\n",
    "airline = pd.read_csv('dados/airline_passengers.csv')\n",
    "airline = airline['valor']\n",
    "airline.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
